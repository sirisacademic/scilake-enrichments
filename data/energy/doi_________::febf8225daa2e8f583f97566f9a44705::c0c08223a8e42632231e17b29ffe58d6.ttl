@prefix lkg-res: <http://lkg.lynx-project.eu/res/> .
@prefix eli:   <http://data.europa.eu/eli/ontology#> .
@prefix owl:   <http://www.w3.org/2002/07/owl#> .
@prefix xsd:   <http://www.w3.org/2001/XMLSchema#> .
@prefix itsrdf: <http://www.w3.org/2005/11/its/rdf#> .
@prefix lkg:   <http://lkg.lynx-project.eu/def/> .
@prefix skos:  <http://www.w3.org/2004/02/skos/core#> .
@prefix nif:   <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-core#> .
@prefix rdfs:  <http://www.w3.org/2000/01/rdf-schema#> .
@prefix dbo:   <http://dbpedia.org/ontology/> .
@prefix qont:  <http://qurator-projekt.de/ontology/> .
@prefix nif-ann: <http://persistence.uni-leipzig.org/nlp2rdf/ontologies/nif-annotation#> .
@prefix dct:   <http://purl.org/dc/terms/> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix dbr:   <http://dbpedia.org/resource/> .
@prefix sci-res: <http://scilake-projekt.eu/res/> .
@prefix foaf:  <http://xmlns.com/foaf/0.1/> .
@prefix scilake: <http://scilake-projekt.eu/ontology/> .

<http://scilake-project.eu/res/cb0fde5c#offset_102_1859>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades." ;
        nif:beginIndex            "102"^^xsd:nonNegativeInteger ;
        nif:endIndex              "1859"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades." ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "abstract" .

<http://scilake-project.eu/res/cb0fde5c#offset_17209_17630>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "In the hope of eliminating the impact of dimension differences between characteristic variables on the prediction results, the coal spontaneous combustion database was made dimensionless through an averaging method using Equation (1). where x ij represents the original data of the jth index of the ith sample; x * ij represents the data after being made dimensionless; and x j represents the mean value of the jth index." ;
        nif:beginIndex            "17209"^^xsd:nonNegativeInteger ;
        nif:endIndex              "17630"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.3." ;
        dct:source                "" ;
        dct:title                 "Data PreProcessing 2.3.1. Making Data Dimensionless" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_15725_16149>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "In the hope of eliminating the impact of dimension differences between characteristic variables on the prediction results, the coal spontaneous combustion database was made dimensionless through an averaging method using Equation (1). where ij x represents the original data of the ùëóth index of the ùëñth sample; ij x * represents the data after being made dimensionless; and j x represents the mean value of the ùëóth index." ;
        nif:beginIndex            "15725"^^xsd:nonNegativeInteger ;
        nif:endIndex              "16149"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.3.1." ;
        dct:source                "" ;
        dct:title                 "Making Data Dimensionless" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_31892_31898>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Step 2" ;
        nif:beginIndex            "31892"^^xsd:nonNegativeInteger ;
        nif:endIndex              "31898"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Collecting data" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_40615_41899>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "To verify the effect of data preprocessing method in this study, firstly, four classic machine learning models were constructed, including one ensemble algorithm, namely RF, and three individual classic algorithms, namely SVM, Bayesian and GBDT. Secondly, the raw database was preprocessed using SMOTE [53,54], Kmeans-SMOTE [55], and Mean-radiusSMOTE. Finally, the prediction effects of these four machine learning models on both the raw and preprocessed coal spontaneous combustion databases were compared using accuracy as the evaluation indicator. The test results are shown in Table 4. After data preprocessing, the accuracy of all algorithms improved to varying degrees and the method proposed in this manuscript was superior to other over-sampling methods. For the dataset processed via the method proposed in this manuscript, GBDT possesses the highest accuracy. Compared with the raw dataset and datasets processed via SMOTE and Kmeans-SMOTE, the accuracy of the method proposed in this manuscript has increased by 49.1%, 23.9% and 10%, respectively. The accuracy of Bayesian is the lowest. However, compared with the raw dataset and datasets processed via SMOTE and Kmeans-SMOTE, the accuracy of the method proposed in this manuscript has increased by 41.5%, 27.1% and 17.2%." ;
        nif:beginIndex            "40615"^^xsd:nonNegativeInteger ;
        nif:endIndex              "41899"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.1." ;
        dct:source                "" ;
        dct:title                 "Verification of Data Preprocessing Effect" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_31885_31891>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Step 1" ;
        nif:beginIndex            "31885"^^xsd:nonNegativeInteger ;
        nif:endIndex              "31891"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "PCA" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_45501_49313>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "To further analyze the prediction results, three sets of comparisons were conducted in this manuscript. Firstly, to verify that Kmeans can cut the computational cost of the model at the expense of lower prediction accuracy, the first set of comparisons was conducted. Secondly, to demonstrate the superiority of FC over Kmeans, a second set of comparisons was made. Finally, the third set of comparisons was conducted to verify the effectiveness of the weight calculated via PCA. The settings of these three sets of comparisons are shown in Table 6. To explore the impact of clustering on the performance of the CBR model, the following comparison groups were introduced in this manuscript: PCA-CBR vs. SO-PCA-Kmeans-CBR and CBR vs. SO-Kmeans-CBR. The comparison results are shown in Table 7 and Figure 11. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall, and F1 of PCA-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 320.01%. Compared with SO-Kmeans-CBR, the accuracy, recall, and F1 of CBR increased by 29.59%, 29.14% and 34.63%, respectively, but the number of comparisons increased by 340%. To sum up, although the application of clustering to the CBR model can reduce the running time of the model and improve its computational efficiency, it also causes information loss, resulting in the lower prediction accuracy of the CBR model.     To verify the superiority of FC over Kmeans, the following control groups were introduced in this study: SO-PCA-FC-CBR vs. SO-PCA-Kmeans-CBR and SO-FC-CBR vs. SO-Kmeans-CBR. The comparison results are displayed in Table 8 and Figure 12. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 140.32%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-FC-CBR increased by 29.59%, 29.41% and 34.63%, respectively, but the number of comparisons increased by 150.83%. In summary, compared with ordinary clustering, although fuzzy clustering increases the computational cost, it avoids the loss of boundary information, preventing the prediction accuracy of the CBR model from declining. To verify the superiority of FC over Kmeans, the following control groups were introduced in this study: SO-PCA-FC-CBR vs. SO-PCA-Kmeans-CBR and SO-FC-CBR vs. SO-Kmeans-CBR. The comparison results are displayed in Table 8 and Figure 12. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 140.32%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-FC-CBR increased by 29.59%, 29.41% and 34.63%, respectively, but the number of comparisons increased by 150.83%. In summary, compared with ordinary clustering, although fuzzy clustering increases the computational cost, it avoids the loss of boundary information, preventing the prediction accuracy of the CBR model from declining.  Finally, to verify the effectiveness of the weight calculated via PCA, this study introduced the following two control groups: SO-PCA-FC-CBR vs. SO-FC-CBR and SO-PCA-Kmeans-CBR vs. SO-Kmeans-CBR. The comparison results are shown in Table 9 and Figure 13. Compared with SO-FC-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 5.32%, 5.01% and 5.32% respectively, and the number of comparisons increased by 0.57%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-Kmeans-CBR increased by 18.68%%, 18.29% and 21.79%, respectively, but the number of comparisons increased by 9.48%. To sum up, the weight calculated via PCA can effectively enhance the prediction performance of CBR and has almost no impact on the computational efficiency of the model." ;
        nif:beginIndex            "45501"^^xsd:nonNegativeInteger ;
        nif:endIndex              "49313"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3.2." ;
        dct:source                "" ;
        dct:title                 "Comparison of Subgroups" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_26657_28651>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "As a commonly used dimensionality reduction algorithm, principal component analysis (PCA) can also calculate the characteristic attribute weights of the data and has achieved good results in multiple fields [51]. Therefore, PCA was used to calculate the characteristic attribute weights of the data in this manuscript. The specific steps are as follows: Step 1: Standardize each case characteristic attribute using Equation (25). where x * ki represents the characteristic description data of the standardized case and x ki represents that of the original case. x l and var(x i ) are calculated using Equations ( 26) and (27). var Step 2: Calculate the Pearson correlation coefficient matrix R between case characteristic attributes based on Equations ( 28) and (29). where r ij is the correlation coefficient between the ith and the jth indicators. Step 3: Calculate the eigenvalues Œª i and eigenvectors ¬µ ij of the correlation coefficient matrix R using the Jacobi method. Step 4: Calculate the number of principal components n using Equation (30). where Œ¥ is the contribution threshold, which is set as 92%; Œª j is the cumulative contribution rate of the top l principal components. Step 5: Calculate the load matrix of principal component factor using Equations (31) and (32). where a ij is the correlation coefficient between the ith indicator and the jth principal components. a ij represents the importance of the ith characteristic attribute of the case for the jth principal component. The smaller the a ij , the less influence of the ith characteristic attribute of the case on the jth principal component; on the contrary, a larger a ij represents a greater influence. Fire 2024, 7, 107 Step 6: Calculate the weight of each indicator on each principal component according to Equation (33), and calculate the weights of case characteristic attributes through Equation (34). where Œ∏ 1 ij denotes the weight of indicator i on principal component j, and Œ∏ i is the weight of indicator i." ;
        nif:beginIndex            "26657"^^xsd:nonNegativeInteger ;
        nif:endIndex              "28651"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1.4." ;
        dct:source                "" ;
        dct:title                 "Weight Value Calculation Based on PCA" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_19368_19368>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "" ;
        nif:beginIndex            "19368"^^xsd:nonNegativeInteger ;
        nif:endIndex              "19368"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3." ;
        dct:source                "" ;
        dct:title                 "Machine Learning Modelling" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_37860_38584>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "In addition, to quantify the improvement ratio of different models, the study introduced ( ) IR i , which is calculated according to Equation (37). Accuracy and F1 are also cited in this study to evaluate the prediction performance of machine learning models, and the calculation formulas are as follows: In addition, to quantify the improvement ratio of different models, the study introduced IR(i), which is calculated according to Equation (37). The bigger the i indicator, the better (B(i) ‚àí A(i))/A(i) The smaller the i indicator, the better (37 where i represents the different evaluation indicators. IR(i) represents the improvement ratio. A(i) and B(i) represent the value of i for model A and model B, respectively." ;
        nif:beginIndex            "37860"^^xsd:nonNegativeInteger ;
        nif:endIndex              "38584"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "TP TN Accuracy TP FP TN FN" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_1860_3617>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades." ;
        nif:beginIndex            "1860"^^xsd:nonNegativeInteger ;
        nif:endIndex              "3617"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades." ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "abstract" .

<http://scilake-project.eu/res/cb0fde5c>
        a                 nif:Context , nif:OffsetBasedString , scilake:ScientificDocument ;
        nif:beginIndex    "0"^^xsd:nonNegativeInteger ;
        nif:endIndex      "58036"^^xsd:nonNegativeInteger ;
        nif:isString      "Prediction of Coal Spontaneous Combustion Hazard Grades Based on Fuzzy Clustered Case-Based Reasoning Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades. Accurate prediction of the coal spontaneous combustion hazard grades is of great significance to ensure the safe production of coal mines. However, traditional coal temperature prediction models have low accuracy and do not predict the coal spontaneous combustion hazard grades. In order to accurately predict coal spontaneous combustion hazard grades, a prediction model of coal spontaneous combustion based on principal component analysis (PCA), case-based reasoning (CBR), fuzzy clustering (FM), and the snake optimization (SO) algorithm was proposed in this manuscript. Firstly, based on the change rule of the concentration of signature gases in the process of coal warming, a new method of classifying the risk of spontaneous combustion of coal was established. Secondly, MeanRadius-SMOTE was adopted to balance the data structure. The weights of the prediction indicators were calculated through PCA to enhance the prediction precision of the CBR model. Then, by employing FM in the case base, the computational cost of CBR was reduced and its computational efficiency was improved. The SO algorithm was used to determine the hyperparameters in the PCA-FM-CBR model. In addition, multiple comparative experiments were conducted to verify the superiority of the model proposed in this manuscript. The results indicated that SO-PCA-FM-CBR possesses good prediction performance and also improves computational efficiency. Finally, the authors of this manuscript adopted the Random Balance Designs-Fourier Amplitude Sensitivity Test (RBD-FAST) to explain the output of the model and analyzed the global importance of input variables. The results demonstrated that CO is the most important variable affecting the coal spontaneous combustion hazard grades. Coal spontaneous combustion, as a common coal mine accident, seriously threatens the lives of coal mine workers and the property safety of mining equipment [1][2][3]. In addition, coal spontaneous combustion also pollutes the soil and destroys the ecological environment [4][5][6]. In recent years, with the depletion of shallow mineral resources, more and more underground coal mine projects are going deeper underground at an unprecedented speed [7][8][9], causing coal spontaneous combustion to become a serious threat to many projects worldwide [10][11][12][13]. To prevent and control coal spontaneous combustion disasters, it is necessary to study the effective prediction of the coal spontaneous combustion method. The gas analysis method, as a commonly used method for predicting spontaneous coal combustion [14], has the advantage of strong operability [15], and is widely used in the prediction of coal spontaneous combustion. This method mainly tests the signature gases generated during the coal heating process and the concentration and finds the variation relationship between it and the coal temperature, thereby indirectly predicting the actual temperature [16]. However, it was found that the relationship between the signature gases' concentration and coal temperature is non-linear [17], and it is very difficult to describe this relationship through the most commonly used mathematical methods. To solve this problem, scholars have applied machine learning to the prediction of spontaneous coal combustion, which, as a branch of artificial intelligence, can better mine the nonlinear relationship between indicators and samples [18]. Zhang [19] proposed a prediction model based on RF and MLP, which can accurately predict coal temperature. However, the model is greatly affected by the value of hyperparameters. Guo [20] and Wang [21] used PSO to calculate the hyperparameters in the GRU and BPNN algorithms, respectively, and established PSO-GRU and PSO-BPNN temperature prediction models. The results show that the models have good prediction ability. Li [22] improved the optimization ability of the GA algorithm and combined it with a neural network to establish a temperature prediction model. The results show that the improved GA algorithm can improve the prediction accuracy of the model. Nonetheless, the aforementioned models have the following limitations: (1) a large number of training samples are required, and the calculation complexity of the model is high, leading to prolonged computational time; (2) most machine learning models do not have self-learning abilities; and (3) they are prone to overfitting during modeling. Therefore, further research is needed to explore new prediction methods. In addition, all of the above studies are quantitative, focusing on predicting coal temperatures, and there are fewer studies on predicting the coal spontaneous combustion hazard grades. As a mature branch of artificial intelligence, case-based reasoning (CBR) has been widely applied in other fields [23]. CBR has greater classification performance compared with traditional data mining methods [24] and it has also shown excellent performance in fields like fault diagnosis [25][26][27], risk assessment [28,29], and forest fire prediction [30][31][32]. It should be noted that the weights of case characteristic attributes in CBR have a significant impact on the prediction performance of the model. However, the calculation of weights lacks a solid foundation and is strongly influenced by subjective factors. In addition, as the number of cases in case-based reasoning becomes larger, the computational cost of CBR gradually increases and the computational efficiency gradually decreases. To address this issue, scholars have applied clustering to the CBR case library [33][34][35], dividing the case library into several different clusters and limiting the CBR process to specific clusters, which reduces the comparison times and lowers the computational cost. However, this method may lead to the loss of cluster boundary information and result in a lower accuracy of model prediction [36]. In addition, concerning the determination of the coal spontaneous combustion hazard grades, scholars have proposed various methods for determining the coal spontaneous combustion hazard grades [37][38][39]. However, due to the different geological structures, mining environments, coal quality composition, and other factors in different coal mines, there are great differences in the numerical values of the same gas indexes, resulting in the absence of a fixed value for the threshold of the coal spontaneous combustion hazard grades, which also poses a challenge to the prediction of the coal spontaneous combustion hazard grades. Although the CBR model possesses good prediction performance in other fields, it has been seldom applied to coal spontaneous combustion hazard grade prediction. Furthermore, there are efficiency bottlenecks and a lack of basis for the weights of case characteristic attributes in the CBR model. In addition, there are some limitations in the current method of classifying the risk level of spontaneous coal combustion. There are also limitations in the current methods of classifying the coal spontaneous combustion hazard grades. Therefore, to address the shortcomings of existing research, the following studies were conducted by the authors of this manuscript: (1) Through analyzing the change rule of signature gases in the process of coal warming, the method of coal spontaneous combustion hazard grade classification was proposed; (2) adaption of PCA to calculate the weights of case characteristic attributes; (3) application of fuzzy clustering to the CBR model to  The data in this paper are from experimental data on the warming of the coal autogenous combustion program [40], which was published publicly by Jiang during his research. The coal samples used in this experiment were from the Dongtan mine coal in Shandong Province, China and the experimental steps are as follows: (1) The coal sample is crushed, 200 g coal sample is selected, including different particle sizes, and mixed to obtain the mixed coal sample; (2) a 1000 g mixed coal sample is placed into the programmed heating device for heating, where the heating rate is 0.3 ‚Ä¢ C/min, and the air supply is 120 mL/min; (3) the gas product is determined, and heating is stopped when the temperature rises to a predetermined temperature. A device for coal spontaneous combustion temperature programming was used to heat coal samples with different particle sizes and test the gas products produced by different coal samples. A total of 337 sets of coal spontaneous combustion data were obtained from this experiment, where each set of data included CO, CH 4 , and CO 2 characteristic indicators. However, the selected index gas values should not only change with the change in temperature but also have an accurate relationship with the coal temperature, due to the presence of CO 2 in the tunnel and the respiratory gases of the workers, and because CH 4 is originally stored in the coal seam, these two indicators are subject to large external influences, and there is no accurate relationship between them and the coal temperature; therefore, we did not choose the CO 2 -related indicators or CH 4 -related indicators. In addition, when we selected the indicators, we reviewed a large number of studies, and many scholars chose CO, CO/‚àÜO 2 , C 2 H 4 /C 2 H 6 , C 2 H 4 , and O 2 when selecting the indicators [15,41,42], and they all thought that these five indicators could reflect the danger level of spontaneous combustion of coal. This paper is based on the classification standard of the coal spontaneous combustion hazard class proposed by scholars, combined with the law of collecting the signature gas in the data of coal spontaneous combustion. Article 261 of the Coal Mine Safety Regulations requires the determination of the signifying gas of natural ignition of coal seams as well as the critical value. Article 265 stipulates that the operation must be stopped when there is a sign of ignition, and Article 275 stipulates that when there is a fire, it should be extinguished immediately according to the nature of the fire and other circumstances. These three articles qualitatively describe the signature gases of spontaneous coal combustion, signs of ignition, and fire, but lack a quantitative method of judgment. Pan [43] divided the stage of spontaneous coal combustion into four stages, but the division criteria are vague and not detailed enough; therefore, we took Pan's criteria as the basis, combined with the division criteria established in the papers published by Duo [41] and Fei [44], and obtained the division criteria in Table 1, which divide the stage of spontaneous coal combustion into six stages, with a higher concentration of O 2 and a lower concentration of CO as the first stage. When CO appears, it is the second stage, when C 2 H 4 gas appears, it is the third stage, when CO/‚àÜO 2 shows an increasing state, it is the fourth stage, a constant C 2 H 4 /C 2 H 6 value, and a decreasing O 2 concentration is the fifth stage, and a maximum C 2 H 4 /C 2 H 6 value is the sixth stage. Figure 1a shows that the O 2 concentration with the increase in temperature shows an overall decreasing trend and when the temperature is less than 50 degrees Celsius, the O 2 concentration is higher, which indicates that the spontaneous combustion of coal at this time is in the first stage. Figure 1b shows that with the increase in temperature, the CO concentration shows an overall increasing trend and when the temperature is greater than 50 degrees Celsius, the CO concentration begins to fluctuate, which indicates that the spontaneous combustion of coal is in the second stage. Figure 1c shows that the C 2 H 4 concentration increases with temperature, and when the temperature is greater than 60 ‚Ä¢ C, the C 2 H 4 concentration fluctuates slightly, which indicates that the spontaneous combustion of coal is in the third stage. Figure 1d shows that CO/‚àÜO 2 increases with temperature, and when the temperature is less than 100 ‚Ä¢ C, the CO/‚àÜO 2 value increases with temperature. When the temperature is greater than 100 ‚Ä¢ C, CO/‚àÜO 2 shows a rapid increase with the increase in temperature, which indicates that the spontaneous combustion of coal is in the fourth stage. Figure 1e shows that the C 2 H 4 /C 2 H 6 concentration with the increased temperature shows an overall increasing trend and when the temperature is between 120 ‚Ä¢ C and 230 ‚Ä¢ C, C 2 H 4 /C 2 H 6 shows an increasing trend with the increase in temperature, which indicates that the spontaneous combustion of coal is in the fifth stage, and when the temperature is greater than 230 ‚Ä¢ C, the highest value appears, which indicates that the spontaneous combustion of coal is in the sixth stage. According to the non-linear relationship between gas and temperature shown in Figure 1, combined with the classification criteria in Table 1, the six stages of coal spontaneous combustion correspond to six warning grades, thus selecting 50 ‚Ä¢ C, 60 ‚Ä¢ C, 100 ‚Ä¢ C, 120 ‚Ä¢ C, 230 ‚Ä¢ C as the temperature thresholds and classifying combustion hazards. The six stages of coal spontaneous combustion correspond to six warning grades, so that 50 ‚Ä¢ C, 60 ‚Ä¢ C, 100 ‚Ä¢ C, 120 ‚Ä¢ C and 230 ‚Ä¢ C are selected as the temperature thresholds, and the combustion hazard grades are divided into six levels: green, blue, purple, yellow, orange and red. The coal spontaneous combustion hazard grades are shown in Table 2. Figure 2 shows that the data in the coal spontaneous combustion hazard grades database exhibit obvious unbalancedness. The proportions for Grades 0-5 are 3.2% (11 cases), 9.2% (31 cases), 30.3% (102 cases), 29.1% (98 cases), 18.9% (64 cases) and 9.2% (31 cases), respectively.    The sixth stage 230 T ‚â• Red warning (5) Figure 2 shows that the data in the coal spontaneous combustion hazard grades database exhibit obvious unbalancedness. The proportions for Grades 0-5 are 3.2% (  In the hope of eliminating the impact of dimension differences between characteristic variables on the prediction results, the coal spontaneous combustion database was made dimensionless through an averaging method using Equation (1). where ij x represents the original data of the ùëóth index of the ùëñth sample; ij x * represents the data after being made dimensionless; and j x represents the mean value of the ùëóth index. As shown in Section 2.2, the initial coal spontaneous combustion dataset is imbalanced, which may lead machine learning models to misclassify minority class samples as majority class samples, thereby affecting their prediction performance. Hence, it is necessary to perform over-sampling with the initial coal spontaneous combustion database. In this manuscript, the MeanRadius-SMOTE algorithm was used to generate new data to achieve balance between various coal spontaneous combustion data [45]. The MeanRadius-SMOTE algorithm modifies the generation rule of the SMOTE algorithm by considering the radius and geometric center when generating new data. As a result, the new samples are more likely to be distributed around the average radius of the minority class samples. This algorithm is not only efficient for datasets of any shape dataset, but also the generated new data are more likely to be distributed near the average radius of the minority class samples, which can improve the ability of machine learning models to identify the decision boundary. In the hope of eliminating the impact of dimension differences between characteristic variables on the prediction results, the coal spontaneous combustion database was made dimensionless through an averaging method using Equation (1). where x ij represents the original data of the jth index of the ith sample; x * ij represents the data after being made dimensionless; and x j represents the mean value of the jth index. As shown in Section 2.2, the initial coal spontaneous combustion dataset is imbalanced, which may lead machine learning models to misclassify minority class samples as majority class samples, thereby affecting their prediction performance. Hence, it is necessary to perform over-sampling with the initial coal spontaneous combustion database. In this manuscript, the MeanRadius-SMOTE algorithm was used to generate new data to achieve balance between various coal spontaneous combustion data [45]. The MeanRadius-SMOTE algorithm modifies the generation rule of the SMOTE algorithm by considering the radius and geometric center when generating new data. As a result, the new samples are more likely to be distributed around the average radius of the minority class samples. This algorithm is not only efficient for datasets of any shape dataset, but also the generated new data are more likely to be distributed near the average radius of the minority class samples, which can improve the ability of machine learning models to identify the decision boundary. The steps of MeanRadius-SMOTE for generating new data are as follows: (  Fire 2024, 7, 107 7 of 25 (5) Repeat Steps 3 and 4 until the sample size of the majority and minority class is balanced. In order to ensure that the generated data are valid, we assigned k as 3 and r as 2 (which is obtained through multiple experiments). After balancing the dataset, 91 new green warning data, 71 blue warning data, 4 yellow warning data, 38 orange warning data, and 71 red warning data were newly generated. The new coal spontaneous combustion database has a total of 510 coal spontaneous combustion data, and the quantity ratio for coal spontaneous combustion of Grades 0-5 is 1:1:1:1.   Case-based reasoning (CBR) is a machine learning algorithm proposed by Aamodt and Plaza et al. in 1994 that mimics the analogical reasoning in the human brain [46]. CBR consists of four basic processes: case representation, case retrieval, case reuse and case retain [30,47]. The schematic diagram of CBR is depicted in Figure 3, and the specific steps are as follows: , 7, 107 8 of 27 Step 3: Sort the similarity values in descending order, and select the top œÉ cases 1 T , 3 T , ‚Ä¶, T œÉ as similar cases. According to the reuse principle, Equation ( 6) was used to obtain the result. Step 4: Store the corresponding target cases and results in the historical case base to complete the knowledge storage and experience learning of CBR. The fuzzy c-means clustering (FCM) algorithm is a clustering algorithm based on objective functions [48]. This algorithm introduces membership functions on the basis of the K-Means algorithm, which can better indicate the similarity between a sample and a certain cluster. The FCM objective function is shown in Equation ( 7). ( ) ( , ) where c is the total number of all categories; m is the weighting fuzziness parameter that is set as 2 in this manuscript; n represents the number of cases in the case base; ik u denotes the membership degree of the k th case with respect to the i th category; 2 ( , ) j i d x v is the distance between the k th case and the ith cluster center. Using the Lagrange multiplier method, the iterative formulas for ik u and i v were obtained as follows. Step 1: Assume that the source cases in the historical database are represented in the following binary format: where m denotes the sum of historical cases; X k denotes the case characteristic attribute; x k is the characteristic data from case descriptions; Y k is the case category. Step 2: Calculate the similarity between the new case and the cases in the case base using Equation (5). where Œ∏ i represents the weights of case characteristic attributes and it is typically set as 1 o . The value of Œ∏ i indicates the contribution degree of a specific characteristic attribute to the overall case. Step 3: Sort the similarity values in descending order, and select the top œÉ cases T 1 , T 2 , T 3 , . . ., T œÉ as similar cases. According to the reuse principle, Equation ( 6) was used to obtain the result. Step 4: Store the corresponding target cases and results in the historical case base to complete the knowledge storage and experience learning of CBR. The fuzzy c-means clustering (FCM) algorithm is a clustering algorithm based on objective functions [48]. This algorithm introduces membership functions on the basis of the K-Means algorithm, which can better indicate the similarity between a sample and a certain cluster. The FCM objective function is shown in Equation (7). where c is the total number of all categories; m is the weighting fuzziness parameter that is set as 2 in this manuscript; n represents the number of cases in the case base; u ik denotes the membership degree of the kth case with respect to the ith category; d 2 (x j , v i ) is the distance between the kth case and the ith cluster center. Using the Lagrange multiplier method, the iterative formulas for u ik and v i were obtained as follows. The authors set the maximum iterations. When the relevant parameters were input, u ik and v i were continuously updated. When the maximum number of iterations was reached or the set conditions were met, the iterations were stopped. Then, the membership matrix, cluster centers and individual clusters were output. The Snake Optimization (SO) algorithm is a new metaheuristic algorithm proposed by Fatma A. Hashim et al. in 2022 [49]. This algorithm is inspired by the mating behavior of snakes in nature. Compared with other algorithms, SO has higher precision and faster iteration speed [50]. The algorithm includes the following four stages: initialization stage, selection stage, exploration stage and development stage (see Figure 4). The specific process is as follows. Step 1: Initialization stage. Generate an initial population using Equation (10), and then divide the population into female and male two swarms using Equations ( 11) and ( 12). where x i represents the location of the ith individual; r is the random number between 0 and 1; x max and x min are the upper and lower limits for x; N represents the number of individuals; N m denotes the number of individuals in the male population, while N f denotes the number of individuals in the female population. Step 2: Selection stage. By calculating the temperature T emp and food quantity Q, the search stage is selected. T emp and Q are calculated using Equations ( 13) and ( 14), respectively. where t denotes the number of present iterations; T is the maximum number of iterations; C 1 is a constant of 0.5. Step 3: Exploration stage. When the food quantity Q is below the threshold, male snakes update their positions using Equations ( 15) and ( 16), while female snakes update their positions using Equations ( 17) and (18). where X i,m and X i, f are the locations of the ith male and female snakes, respectively; X rand,m and X rand, f are the randomly selected locations of male and female snakes. c 2 is a constant that is set as 0.05; A m and A f represent the ability of male and female snakes to search for food; rand is a random number between 0 and 1. f rand,m and f rand, f are the fitness of X rand,m and X rand, f ; f i,m and f i, f represent the fitness of the ith individuals of male and female snakes. Step 4: Development stage. When the food quantity Q is greater than the threshold, the development stage is divided into two parts according to the temperature. When the temperature is greater than the threshold, the snake is in a thermal state and it only searches for food. The position update equation is shown as follows: where X i,j (t + 1) represents the location of the female or male snake; X f ood is the best individual location and c 3 is a constant that is set as 0.05. As the number of iterations increases, the temperature decreases gradually. When the temperature is lower than the threshold, the snake is in a cold state. In this state, the snake updates its position through fighting or mating. The equation for updating the position in fight mode is shown in Equation (20). where X i,m (t + 1) and X i, f (t + 1) denote the locations of the ith male and female snakes. X best,m and X best, f denote the best location of male and female snakes. FM and FF represent the fighting capability of the male and female snakes, which are calculated via Equation (21). where f best,m and f best, f represent the fitness of the best male and female snakes; f i represents the fitness of individual i. Fire 2024, 7, 107 10 of 25   The updated position equation for the mating mode is depicted as follows: where X i,m (t) and X i, f (t) are the locations of the ith snakes in the male and female swarms, respectively; M m and M f are the mating competence values of male and female snakes, which are calculated as follows: If the snake eggs hatch, the worst individuals in the male swarm and female swarm are exchanged using the following equation: where X worst,m and X worst, f represent the worst individuals in male and female swarms. As a commonly used dimensionality reduction algorithm, principal component analysis (PCA) can also calculate the characteristic attribute weights of the data and has achieved good results in multiple fields [51]. Therefore, PCA was used to calculate the characteristic attribute weights of the data in this manuscript. The specific steps are as follows: Step 1: Standardize each case characteristic attribute using Equation (25). where x * ki represents the characteristic description data of the standardized case and x ki represents that of the original case. x l and var(x i ) are calculated using Equations ( 26) and (27). var Step 2: Calculate the Pearson correlation coefficient matrix R between case characteristic attributes based on Equations ( 28) and (29). where r ij is the correlation coefficient between the ith and the jth indicators. Step 3: Calculate the eigenvalues Œª i and eigenvectors ¬µ ij of the correlation coefficient matrix R using the Jacobi method. Step 4: Calculate the number of principal components n using Equation (30). where Œ¥ is the contribution threshold, which is set as 92%; Œª j is the cumulative contribution rate of the top l principal components. Step 5: Calculate the load matrix of principal component factor using Equations (31) and (32). where a ij is the correlation coefficient between the ith indicator and the jth principal components. a ij represents the importance of the ith characteristic attribute of the case for the jth principal component. The smaller the a ij , the less influence of the ith characteristic attribute of the case on the jth principal component; on the contrary, a larger a ij represents a greater influence. Fire 2024, 7, 107 Step 6: Calculate the weight of each indicator on each principal component according to Equation (33), and calculate the weights of case characteristic attributes through Equation (34). where Œ∏ 1 ij denotes the weight of indicator i on principal component j, and Œ∏ i is the weight of indicator i. The traditional PCA-clustering-CBR model is a hybrid model that applies PCA and clustering to CBR. To some extent, this model solves the problem that the weights of case characteristic attributes are difficult to determine in the traditional CBR model and the case retrieval efficiency is reduced as the case increases in the case base. The PCA-clustering-CBR model first adopts the PCA algorithm to calculate the basic weights of case characteristic attributes and applies them to the calculation of similarity, which increases the calculation accuracy and improves the prediction ability. In order to improve the efficiency of case retrieval, a clustering algorithm is used to divide n cases in the case base into k clusters with cluster centers serving as representative cases. The mean value of each data point in each cluster is taken. When a new problem arises, it is first compared with cluster centers, and then assigned to the most relevant cluster, where the entire CBR process is conducted. However, this model may cause the loss of cluster boundary information, reducing the prediction ability of the machine learning model and affecting its generalization ability. To find a solution to the aforementioned problem, we introduced fuzzy clustering into CBR to construct the PCA-FC-CBR model. The case base was divided into sets of fuzzy clusters with overlapping boundaries, allowing any case to belong to multiple clusters simultaneously. During the prediction process, cases are screened based on their membership degree with respect to the cluster centers, thereby reducing the loss of boundary information.  The flowchart of model construction is shown in Figure 5 and the steps of model construction are shown as follows: Fire 2024, 7, 107 14 of 27 Step 2: Data preprocessing. Initially, stratify the hazard grades associated with spontaneous coal combustion. Subsequently, apply dimensionless normalization to the dataset. Finally, equalize the dataset distribution through the implementation of the Mean-Radius-SMOTE algorithm. Step 3: Divide the coal spontaneous combustion data into a training set and a test set, using the training set data to construct a coal spontaneous combustion database. The test set data are used to verify the model's performance. Apply the FCM algorithm to perform fuzzy clustering on the coal spontaneous combustion database, obtaining cluster centers and membership functions. Construct a fuzzy clustering CBR model. Step 4: Set the cumulative contribution rate and calculate the weights of each case characteristic attribute using PCA. Step 5: Primary case retrieval. Firstly, screen out the cluster centers whose similarity with the new case is no less than 1 Œ≥ (similarity threshold). Secondly, screen out all cases whose membership degree with cluster centers is greater than 2 Œ≥ (similarity threshold), form a new case library with the filtered cases. Step 6: Secondary case retrieval. Sort the similarity degrees from largest to smallest and take the top œÉ cases as similar cases. Determine the coal spontaneous combustion hazard grades on the basis of the majority rule principle. If there is a case with a similarity of 1 to X in D , take the case as the matching one for X . Step 1 Step 2 Step 3 Developing the Case Base Step 5 Step 4 Assigning the Attribute Weights Step 6 Fristly retrieval The effectiveness of machine learning models largely depends on parameter selection. If parameters are selected based on empirical selection or grid search, deep learning models may experience overfitting or underfitting. Furthermore, since there are many hyperparameters, it is often difficult to set their values through experience alone. Therefore,  Step 1: Collect coal spontaneous combustion data, screen prediction indicators for coal spontaneous combustion, and analyze the data to build a raw coal spontaneous combustion data base. Step 2: Data preprocessing. Initially, stratify the hazard grades associated with spontaneous coal combustion. Subsequently, apply dimensionless normalization to the dataset. Finally, equalize the dataset distribution through the implementation of the MeanRadius-SMOTE algorithm. Step 3: Divide the coal spontaneous combustion data into a training set and a test set, using the training set data to construct a coal spontaneous combustion database. The test set data are used to verify the model's performance. Apply the FCM algorithm to perform fuzzy clustering on the coal spontaneous combustion database, obtaining cluster centers and membership functions. Construct a fuzzy clustering CBR model. Step 4: Set the cumulative contribution rate and calculate the weights of each case characteristic attribute using PCA. Step 5: Primary case retrieval. Firstly, screen out the cluster centers whose similarity with the new case is no less than Œ≥ 1 (similarity threshold). Secondly, screen out all cases whose membership degree with cluster centers is greater than Œ≥ 2 (similarity threshold), form a new case library with the filtered cases. Step 6: Secondary case retrieval. Sort the similarity degrees from largest to smallest and take the top œÉ cases as similar cases. Determine the coal spontaneous combustion hazard grades on the basis of the majority rule principle. If there is a case with a similarity of 1 to X in D, take the case as the matching one for X. The effectiveness of machine learning models largely depends on parameter selection. If parameters are selected based on empirical selection or grid search, deep learning models may experience overfitting or underfitting. Furthermore, since there are many hyperparameters, it is often difficult to set their values through experience alone. Therefore, the SO algorithm was adopted to identify the hyperparameters in the PCA-clustering-CBR hybrid model in this research. Table 3 displays the hyperparameters in PCA-clustering-CBR that require adjustment and their respective ranges of values. The number of iterations was set as 100 with 10 individuals in each generation. All parameters in the SO algorithm were set through experimental testing. During hyperparameter tuning, each set of hyperparameters is represented by a snake in the SO algorithm. The SO algorithm was adopted to update the position of each snake by using different optimization formulas at different stages. Hence, the fitness value was minimized. When meeting the termination condition, the optimal hyperparameters were selected. To ensure both the computational efficiency and prediction precision of the model, the authors set the accuracy rate and the number of comparisons as the objective function. For multiple objective functions, the optimization process was set as follows: (1) initialize the parameters of the SO algorithm. (2) Use the accuracy rate as the objective function to find the optimal parameter for PCA-clustering-CBR. (3) Find the optimal parameter for PCA-clustering-CBR by setting the highest accuracy as the limiting condition and the number of comparisons as the objective function. The data was divided into two sets, with the first 70% used as the training set to create and train the SO-PCA-clustering-CBR model, and the remaining 30% used as the test set to evaluate the model performance. Accuracy and recall are commonly used indicators to evaluate the predictive ability of classification models. They are calculated through a confusion matrix, as demonstrated in Figure 6. The confusion matrix is widely used to evaluate the prediction precision of classification models in binary classification. For the confusion matrix of multi-class classification problems, each category is successively considered as positive, while other categories are considered as negative, thus converting the multi-class classification problem into multiple binary classification problems [52]. The specific schematic diagram is shown in Figure 6. the parameters of the SO algorithm. ( 2) Use the accuracy rate as the objective function to find the optimal parameter for PCA-clustering-CBR. (3) Find the optimal parameter for PCA-clustering-CBR by setting the highest accuracy as the limiting condition and the number of comparisons as the objective function.  The data was divided into two sets, with the first 70% used as the training set to create and train the SO-PCA-clustering-CBR model, and the remaining 30% used as the test set to evaluate the model performance. Accuracy and recall are commonly used indicators to evaluate the predictive ability of classification models. They are calculated through a confusion matrix, as demonstrated in Figure 6. The confusion matrix is widely used to evaluate the prediction precision of classification models in binary classification. For the confusion matrix of multi-class classification problems, each category is successively considered as positive, while other categories are considered as negative, thus converting the multi-class classification problem into multiple binary classification problems [52]. The specific schematic diagram is shown in Figure 6. Accuracy and F1 are also cited in this study to evaluate the prediction performance of machine learning models, and the calculation formulas are as follows: In addition, to quantify the improvement ratio of different models, the study introduced ( ) IR i , which is calculated according to Equation (37). Accuracy and F1 are also cited in this study to evaluate the prediction performance of machine learning models, and the calculation formulas are as follows: In addition, to quantify the improvement ratio of different models, the study introduced IR(i), which is calculated according to Equation (37). The bigger the i indicator, the better (B(i) ‚àí A(i))/A(i) The smaller the i indicator, the better (37 where i represents the different evaluation indicators. IR(i) represents the improvement ratio. A(i) and B(i) represent the value of i for model A and model B, respectively. To verify the superior performance of the proposed model in this manuscript, multiple sets of comparative experiments were designed as depicted in Figure 7. The specific steps are as follows: Step 3: Verification, comparison and visualization of results. To verify the performance of the proposed SO-PCA-FC-CBR model in this study, the above-mentioned six single models and three hybrid models were compared with each other when predicting the hazard grades of coal spontaneous combustion. All models were based on the same dataset. The accuracy, precision, recall, and F1 index were selected as evaluation indicators to verify the prediction effect of the models on the test set.  Step 1: Data Preprocessing. Firstly, the data were collected and analyzed. Secondly, based on the analysis of the data, the hazard classification criteria for the spontaneous coal combustion data were established. Thirdly, the data were dimensionless and balanced by the MeanRadius-SMOTE method. Finally, the dataset was divided into a training set and test set in the ratio of 7:3. Step 2: Model construction. Firstly, the SO-PCA-FC-CBR model and other comparative models were built, and the training samples were inputted to train the prediction models. Accuracy was used as the objective function, while the SO algorithm was used to determine the hyperparameters of the models. Secondly, five single models (SVM, RF, Bayesian, GBDT and CBR) and five hybrid models (PCA-CBR, SO-PCA-Kmeans-CBR, SO-Kmeans-CBR, SO-PCA-FC-CBR and SO-FC-CBR) were constructed. Step 3: Verification, comparison and visualization of results. To verify the performance of the proposed SO-PCA-FC-CBR model in this study, the above-mentioned six single models and three hybrid models were compared with each other when predicting the hazard grades of coal spontaneous combustion. All models were based on the same dataset. The accuracy, precision, recall, and F1 index were selected as evaluation indicators to verify the prediction effect of the models on the test set.  To verify the effect of data preprocessing method in this study, firstly, four classic machine learning models were constructed, including one ensemble algorithm, namely RF, and three individual classic algorithms, namely SVM, Bayesian and GBDT. Secondly, the raw database was preprocessed using SMOTE [53,54], Kmeans-SMOTE [55], and Mean-radiusSMOTE. Finally, the prediction effects of these four machine learning models on both the raw and preprocessed coal spontaneous combustion databases were compared using accuracy as the evaluation indicator. The test results are shown in Table 4. After data preprocessing, the accuracy of all algorithms improved to varying degrees and the method proposed in this manuscript was superior to other over-sampling methods. For the dataset processed via the method proposed in this manuscript, GBDT possesses the highest accuracy. Compared with the raw dataset and datasets processed via SMOTE and Kmeans-SMOTE, the accuracy of the method proposed in this manuscript has increased by 49.1%, 23.9% and 10%, respectively. The accuracy of Bayesian is the lowest. However, compared with the raw dataset and datasets processed via SMOTE and Kmeans-SMOTE, the accuracy of the method proposed in this manuscript has increased by 41.5%, 27.1% and 17.2%. Figure 8 shows the iterative process of the SO algorithm searching for the maximum accuracy. It can be seen that as the SO algorithm iterates, the accuracy gradually increases, indicating that the SO algorithm is effective at optimizing the hyperparameters of the SO-PCA-FC-CBR hybrid model. The accuracy is the lowest (0.71) at the first iteration, and it increases to 0.95 at the 36th iteration. Figure 9 demonstrates the iterative process of the SO algorithm searching for the minimum number of comparisons. The figure illustrates that as the SO algorithm iterates, the number of comparisons gradually decreases, indicating that the SO algorithm is also effective at improving the computational efficiency of the SO-PCA-FC-CBR hybrid model. The number of comparisons is the highest at the first iteration, which is 78,752, and then decreases to 45,000 at the 45th iteration.  In order to verify the performance of the model proposed in this m single models (SVM, RF, Bayesian, GBDT and CBR) and two hybrid mo Kmeans-CBR and SO-Kmeans-CBR) were compared with each other by predict coal spontaneous combustion hazard grades. Table 5 shows the F1 curacy of SO-PCA-FC-CBR and other models at each intensity grade (0-5 spontaneous combustion. In the prediction of initial values for warning, SO has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. In of gray warning, SO-PCA-FC-CBR has the highest F1-score, recall, and ac 1, and 0.97, respectively. In the prediction of blue warning, CBR and RF h  In order to verify the performance of the model proposed in this manuscript, five single models (SVM, RF, Bayesian, GBDT and CBR) and two hybrid models (SO-PCA-Kmeans-CBR and SO-Kmeans-CBR) were compared with each other by using them to predict coal spontaneous combustion hazard grades. Table 5 shows the F1, recall, and accuracy of SO-PCA-FC-CBR and other models at each intensity grade (0-5 levels) of coal spontaneous combustion. In the prediction of initial values for warning, SO-PCA-FC-CBR has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. In the prediction of gray warning, SO-PCA-FC-CBR has the highest F1-score, recall, and accuracy of 0.98, 1, and 0.97, respectively. In the prediction of blue warning, CBR and RF have the highest accuracy of 1, while SO-PCA-FC-CBR has the highest F1-score and recall of 0.97 and 0.97, respectively. In the prediction of yellow warning, RF has the highest recall of 1, while SO-PCA-FC-CBR has the highest F1-score and accuracy of 1 and 0.98, respectively. In the prediction of orange warning, SVM has the highest F1 of 1, SO-PCA-FC-CBR has the highest recall of 0.81 and RF has the highest accuracy of 1. In the prediction of red warning, SVM has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. Overall, SO-PCA-FC-CBR shows the best predictive performance for all of the six coal spontaneous combustion hazard grades. Figure 10 shows the overall accuracy of five single models, two hybrid models and the model proposed in this manuscript. Evidently, the SO-PCA-FC-CBR model possesses the highest overall accuracy of 95%, demonstrating the superiority of the proposed algorithm in predicting coal spontaneous combustion hazard grades. To further analyze the prediction results, three sets of comparisons were conducted in this manuscript. Firstly, to verify that Kmeans can cut the computational cost of the model at the expense of lower prediction accuracy, the first set of comparisons was conducted. Secondly, to demonstrate the superiority of FC over Kmeans, a second set of com- To further analyze the prediction results, three sets of comparisons were conducted in this manuscript. Firstly, to verify that Kmeans can cut the computational cost of the model at the expense of lower prediction accuracy, the first set of comparisons was conducted. Secondly, to demonstrate the superiority of FC over Kmeans, a second set of comparisons was made. Finally, the third set of comparisons was conducted to verify the effectiveness of the weight calculated via PCA. The settings of these three sets of comparisons are shown in Table 6. To explore the impact of clustering on the performance of the CBR model, the following comparison groups were introduced in this manuscript: PCA-CBR vs. SO-PCA-Kmeans-CBR and CBR vs. SO-Kmeans-CBR. The comparison results are shown in Table 7 and Figure 11. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall, and F1 of PCA-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 320.01%. Compared with SO-Kmeans-CBR, the accuracy, recall, and F1 of CBR increased by 29.59%, 29.14% and 34.63%, respectively, but the number of comparisons increased by 340%. To sum up, although the application of clustering to the CBR model can reduce the running time of the model and improve its computational efficiency, it also causes information loss, resulting in the lower prediction accuracy of the CBR model.     To verify the superiority of FC over Kmeans, the following control groups were introduced in this study: SO-PCA-FC-CBR vs. SO-PCA-Kmeans-CBR and SO-FC-CBR vs. SO-Kmeans-CBR. The comparison results are displayed in Table 8 and Figure 12. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 140.32%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-FC-CBR increased by 29.59%, 29.41% and 34.63%, respectively, but the number of comparisons increased by 150.83%. In summary, compared with ordinary clustering, although fuzzy clustering increases the computational cost, it avoids the loss of boundary information, preventing the prediction accuracy of the CBR model from declining. To verify the superiority of FC over Kmeans, the following control groups were introduced in this study: SO-PCA-FC-CBR vs. SO-PCA-Kmeans-CBR and SO-FC-CBR vs. SO-Kmeans-CBR. The comparison results are displayed in Table 8 and Figure 12. Compared with SO-PCA-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 15.01%, 14.73% and 16.42%, respectively, but the number of comparisons increased by 140.32%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-FC-CBR increased by 29.59%, 29.41% and 34.63%, respectively, but the number of comparisons increased by 150.83%. In summary, compared with ordinary clustering, although fuzzy clustering increases the computational cost, it avoids the loss of boundary information, preventing the prediction accuracy of the CBR model from declining.  Finally, to verify the effectiveness of the weight calculated via PCA, this study introduced the following two control groups: SO-PCA-FC-CBR vs. SO-FC-CBR and SO-PCA-Kmeans-CBR vs. SO-Kmeans-CBR. The comparison results are shown in Table 9 and Figure 13. Compared with SO-FC-CBR, the accuracy, recall and F1 of SO-PCA-FC-CBR increased by 5.32%, 5.01% and 5.32% respectively, and the number of comparisons increased by 0.57%. Compared with SO-Kmeans-CBR, the accuracy, recall and F1 of SO-PCA-Kmeans-CBR increased by 18.68%%, 18.29% and 21.79%, respectively, but the number of comparisons increased by 9.48%. To sum up, the weight calculated via PCA can effectively enhance the prediction performance of CBR and has almost no impact on the computational efficiency of the model. To calculate the relative importance of coal spontaneous combustion characteristic variables, this manuscript took SO-PCA-FC-CBR as the target function and adopted the random balance design Fourier amplitude sensitivity test (RBD-FAST) method to carry out sensitivity analysis on characteristic variables. RBD-FAST is a method used to reduce computational costs by implementing the latest developed Fourier amplitude sensitivity test (FAST) using random balance design (RBD) technology [56]. All parameters were set to the same frequency and then reorganized after sampling. Fast Fourier Transform (FFT) was used for the model output based on the previous reorganization sequence. The firstorder sensitivity analysis results of corresponding parameters were recorded [57]. In this method, the changes in the results can be simplified as follows: ( ) To calculate the relative importance of coal spontaneous combustion characteristic variables, this manuscript took SO-PCA-FC-CBR as the target function and adopted the random balance design Fourier amplitude sensitivity test (RBD-FAST) method to carry out sensitivity analysis on characteristic variables. RBD-FAST is a method used to reduce computational costs by implementing the latest developed Fourier amplitude sensitivity test (FAST) using random balance design (RBD) technology [56]. All parameters were set to the same frequency and then reorganized after sampling. Fast Fourier Transform (FFT) was used for the model output based on the previous reorganization sequence. The first-order sensitivity analysis results of corresponding parameters were recorded [57]. In this method, the changes in the results can be simplified as follows: where V x i is the first-order influence of the input factor x i based on the method. V(Y) represents the total variance of SO-PCA-Clustering-CBR. The relative importance of input variables is shown in Figure 14. It can be seen that CO is the most important input variable with a relative importance score of 0.28, followed by CO/‚àÜO 2 (0.23), C 2 H 4 /C 2 H 6 (0.19) and C 2 H 4 (0.17). O 2 (0.13) is the least sensitive predictive factor. The figure illustrates that CO is the most important factor affecting the coal spontaneous combustion hazard grades and this is consistent with the research results of many scholars, but at present, most of the methods used to reach this conclusion have been obtained by observing the chemical reaction of coal molecules and the change law of gas in the temperature program [58][59][60]. However, in this paper, the relative importance of CO is quantified by the RBD-FAST method, and this conclusion is justified by specific values. This method can also be utilized to determine the gases with the greatest relative importance in each stage of coal autogenous combustion, and thus to select the signature gases for each stage of coal autogenous combustion. With the continuous deepening of research in this field, scholars have found more and more factors that influence the spontaneous combustion hazard class of coal [61,62]. However, most of the methods have also been obtained by analyzing the experimental results, which cannot illustrate the importance of the gas in a quantitative manner, while the RBD-FAST method can make up for this shortcoming, providing scholars with a quantitative method to illustrate the newly found importance of the discovered gases through numerical values, which makes the obtained conclusions more convincing. In addition, scholars have established different coal spontaneous combustion stage division systems [41,44], and selected different signature gases in different stages as the basis of discrimination; however, most of the characteristic gas selection methods are based on the change law of different gases in the programmed temperature experiment of coal and the possible chemical reaction of coal molecular groups, but this method does not have specific values, resulting in a lack of persuasion. The RBF-FAST method can quantify the relative importance of each gas at each stage of coal spontaneous combustion, and provide data support for the establishment of coal spontaneous combustion early warning systems. V is the first-order influence of the input factor i x based on the method. ( ) V Y represents the total variance of SO-PCA-Clustering-CBR. The relative importance of input variables is shown in Figure 14. It can be seen that CO is the most important input variable with a relative importance score of 0. The figure illustrates that CO is the most important factor affecting the coal spontaneous combustion hazard grades and this is consistent with the research results of many scholars, but at present, most of the methods used to reach this conclusion have been obtained by observing the chemical reaction of coal molecules and the change law of gas in the temperature program [58,59,60]. However, in this paper, the relative importance of CO is quantified by the RBD-FAST method, and this conclusion is justified by specific values. This method can also be utilized to determine the gases with the greatest relative importance in each stage of coal autogenous combustion, and thus to select the signature gases for each stage of coal autogenous combustion. With the continuous deepening of research in this field, scholars have found more and more factors that influence the spontaneous combustion hazard class of coal [61,62]. However, most of the methods have also been obtained by analyzing the experimental results, which cannot illustrate the importance of the gas in a quantitative manner, while the RBD-FAST method can make up for this shortcoming, providing scholars with a quantitative method to illustrate the newly found importance of the discovered gases through numerical values, which makes the obtained conclusions more convincing. In addition, scholars have established different coal spontaneous combustion stage division systems [41,44], and selected different signature gases in different stages as the basis of discrimination; however, most of the characteristic gas selection methods are based on the change law of different gases in the programmed temperature experiment of coal and the possible chemical reaction of coal molecular groups, but this method does not have specific values, resulting in a lack of In this study, a new method used to obtain coal spontaneous combustion hazard grades is proposed based on the changing law of the concentration of various signature gases in the process of coal spontaneous combustion, and a prediction model of coal spontaneous combustion hazard grades is established. The findings can be summarized as follows: (1) By analyzing the change rule of the experimental data of heating up coal in the spontaneous combustion procedure, six characteristic temperatures and their thresholds were determined, and the hazard classes of coal were classified into six classes: green (0), blue (1), purple (2), yellow (3), orange (4), and red (5). (2) MeanRadius-SMOTE can be adopted to address the imbalance of the dataset. By comparing the predictive ability of four prediction models on different datasets, it was found that the proposed method performs the best when compared to the SMOTE and Kmeans-SMOTE methods. (3) Three sets of comparative experiments were conducted in this research to compare the performance of different machine learning models in predicting coal spontaneous combustion hazard grades. The experimental results indicate that (1) the traditional PCA-Clustering-CBR model reduces the computational cost but also causes boundary information loss, resulting in lower prediction accuracy of machine learning models; (2) compared with the traditional PCA-Clustering-CBR, fuzzy clustering avoids the loss of boundary information and improves the computational efficiency of the model without affecting the prediction accuracy; and (3) PCA can improve the prediction accuracy of machine learning models by calculating characteristic attribute weights based on the cumulative contribution rate. (4) Aiming at the multi-objective optimization problem of the PCA-FM-CBR model, this manuscript adopted the SO algorithm to optimize Œ≥ 1 , Œ≥ 2 and œÉ of the PCA-FM-CBR model step by step. The optimization shows that the model demonstrates optimal performance when the values of Œ≥ 1 , Œ≥ 2 and œÉ are 0.71, 0.39, and 2, respectively. The calculation cost is reduced to the greatest extent. (5) RBD-FAST was used to conduct sensitivity analysis for input variables, and the results demonstrated that CO is the most important input variable with a relative importance score of 0.28. Therefore, attention should be paid to CO in practical underground engineering." ;
        qont:metadata     [ dct:language  "en" ] ;
        scilake:has_part  <http://scilake-project.eu/res/cb0fde5c#offset_16150_17208> , <http://scilake-project.eu/res/cb0fde5c#offset_15724_15724> , <http://scilake-project.eu/res/cb0fde5c#offset_11295_15723> , <http://scilake-project.eu/res/cb0fde5c#offset_30275_31884> , <http://scilake-project.eu/res/cb0fde5c#offset_38585_40613> , <http://scilake-project.eu/res/cb0fde5c#offset_42779_43419> , <http://scilake-project.eu/res/cb0fde5c#offset_9357_9357> , <http://scilake-project.eu/res/cb0fde5c#offset_31899_31937> , <http://scilake-project.eu/res/cb0fde5c#offset_26657_28651> , <http://scilake-project.eu/res/cb0fde5c#offset_36851_36851> , <http://scilake-project.eu/res/cb0fde5c#offset_102_1859> , <http://scilake-project.eu/res/cb0fde5c#offset_0_101> , <http://scilake-project.eu/res/cb0fde5c#offset_20106_21852> , <http://scilake-project.eu/res/cb0fde5c#offset_40615_41899> , <http://scilake-project.eu/res/cb0fde5c#offset_43421_45151> , <http://scilake-project.eu/res/cb0fde5c#offset_34007_35687> , <http://scilake-project.eu/res/cb0fde5c#offset_9358_11294> , <http://scilake-project.eu/res/cb0fde5c#offset_22938_26656> , <http://scilake-project.eu/res/cb0fde5c#offset_35688_36850> , <http://scilake-project.eu/res/cb0fde5c#offset_43420_43420> , <http://scilake-project.eu/res/cb0fde5c#offset_45152_45500> , <http://scilake-project.eu/res/cb0fde5c#offset_30274_30274> , <http://scilake-project.eu/res/cb0fde5c#offset_49314_50163> , <http://scilake-project.eu/res/cb0fde5c#offset_32002_34006> , <http://scilake-project.eu/res/cb0fde5c#offset_37860_38584> , <http://scilake-project.eu/res/cb0fde5c#offset_45501_49313> , <http://scilake-project.eu/res/cb0fde5c#offset_42778_42778> , <http://scilake-project.eu/res/cb0fde5c#offset_3618_9356> , <http://scilake-project.eu/res/cb0fde5c#offset_17631_19367> , <http://scilake-project.eu/res/cb0fde5c#offset_28652_30273> , <http://scilake-project.eu/res/cb0fde5c#offset_17209_17630> , <http://scilake-project.eu/res/cb0fde5c#offset_41900_42777> , <http://scilake-project.eu/res/cb0fde5c#offset_15725_16149> , <http://scilake-project.eu/res/cb0fde5c#offset_21853_22937> , <http://scilake-project.eu/res/cb0fde5c#offset_31938_32001> , <http://scilake-project.eu/res/cb0fde5c#offset_40614_40614> , <http://scilake-project.eu/res/cb0fde5c#offset_19369_19369> , <http://scilake-project.eu/res/cb0fde5c#offset_55646_58036> , <http://scilake-project.eu/res/cb0fde5c#offset_19368_19368> , <http://scilake-project.eu/res/cb0fde5c#offset_19370_20105> , <http://scilake-project.eu/res/cb0fde5c#offset_36852_37859> , <http://scilake-project.eu/res/cb0fde5c#offset_1860_3617> , <http://scilake-project.eu/res/cb0fde5c#offset_31892_31898> , <http://scilake-project.eu/res/cb0fde5c#offset_31885_31891> , <http://scilake-project.eu/res/cb0fde5c#offset_50164_55645> .

<http://scilake-project.eu/res/cb0fde5c#offset_38585_40613>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "To verify the superior performance of the proposed model in this manuscript, multiple sets of comparative experiments were designed as depicted in Figure 7. The specific steps are as follows: Step 3: Verification, comparison and visualization of results. To verify the performance of the proposed SO-PCA-FC-CBR model in this study, the above-mentioned six single models and three hybrid models were compared with each other when predicting the hazard grades of coal spontaneous combustion. All models were based on the same dataset. The accuracy, precision, recall, and F1 index were selected as evaluation indicators to verify the prediction effect of the models on the test set.  Step 1: Data Preprocessing. Firstly, the data were collected and analyzed. Secondly, based on the analysis of the data, the hazard classification criteria for the spontaneous coal combustion data were established. Thirdly, the data were dimensionless and balanced by the MeanRadius-SMOTE method. Finally, the dataset was divided into a training set and test set in the ratio of 7:3. Step 2: Model construction. Firstly, the SO-PCA-FC-CBR model and other comparative models were built, and the training samples were inputted to train the prediction models. Accuracy was used as the objective function, while the SO algorithm was used to determine the hyperparameters of the models. Secondly, five single models (SVM, RF, Bayesian, GBDT and CBR) and five hybrid models (PCA-CBR, SO-PCA-Kmeans-CBR, SO-Kmeans-CBR, SO-PCA-FC-CBR and SO-FC-CBR) were constructed. Step 3: Verification, comparison and visualization of results. To verify the performance of the proposed SO-PCA-FC-CBR model in this study, the above-mentioned six single models and three hybrid models were compared with each other when predicting the hazard grades of coal spontaneous combustion. All models were based on the same dataset. The accuracy, precision, recall, and F1 index were selected as evaluation indicators to verify the prediction effect of the models on the test set." ;
        nif:beginIndex            "38585"^^xsd:nonNegativeInteger ;
        nif:endIndex              "40613"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "4.2." ;
        dct:source                "" ;
        dct:title                 "Experiments and Comparison" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_9358_11294>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "The data in this paper are from experimental data on the warming of the coal autogenous combustion program [40], which was published publicly by Jiang during his research. The coal samples used in this experiment were from the Dongtan mine coal in Shandong Province, China and the experimental steps are as follows: (1) The coal sample is crushed, 200 g coal sample is selected, including different particle sizes, and mixed to obtain the mixed coal sample; (2) a 1000 g mixed coal sample is placed into the programmed heating device for heating, where the heating rate is 0.3 ‚Ä¢ C/min, and the air supply is 120 mL/min; (3) the gas product is determined, and heating is stopped when the temperature rises to a predetermined temperature. A device for coal spontaneous combustion temperature programming was used to heat coal samples with different particle sizes and test the gas products produced by different coal samples. A total of 337 sets of coal spontaneous combustion data were obtained from this experiment, where each set of data included CO, CH 4 , and CO 2 characteristic indicators. However, the selected index gas values should not only change with the change in temperature but also have an accurate relationship with the coal temperature, due to the presence of CO 2 in the tunnel and the respiratory gases of the workers, and because CH 4 is originally stored in the coal seam, these two indicators are subject to large external influences, and there is no accurate relationship between them and the coal temperature; therefore, we did not choose the CO 2 -related indicators or CH 4 -related indicators. In addition, when we selected the indicators, we reviewed a large number of studies, and many scholars chose CO, CO/‚àÜO 2 , C 2 H 4 /C 2 H 6 , C 2 H 4 , and O 2 when selecting the indicators [15,41,42], and they all thought that these five indicators could reflect the danger level of spontaneous combustion of coal." ;
        nif:beginIndex            "9358"^^xsd:nonNegativeInteger ;
        nif:endIndex              "11294"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.1." ;
        dct:source                "" ;
        dct:title                 "Dataset Collection" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_30275_31884>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "The flowchart of model construction is shown in Figure 5 and the steps of model construction are shown as follows: Fire 2024, 7, 107 14 of 27 Step 2: Data preprocessing. Initially, stratify the hazard grades associated with spontaneous coal combustion. Subsequently, apply dimensionless normalization to the dataset. Finally, equalize the dataset distribution through the implementation of the Mean-Radius-SMOTE algorithm. Step 3: Divide the coal spontaneous combustion data into a training set and a test set, using the training set data to construct a coal spontaneous combustion database. The test set data are used to verify the model's performance. Apply the FCM algorithm to perform fuzzy clustering on the coal spontaneous combustion database, obtaining cluster centers and membership functions. Construct a fuzzy clustering CBR model. Step 4: Set the cumulative contribution rate and calculate the weights of each case characteristic attribute using PCA. Step 5: Primary case retrieval. Firstly, screen out the cluster centers whose similarity with the new case is no less than 1 Œ≥ (similarity threshold). Secondly, screen out all cases whose membership degree with cluster centers is greater than 2 Œ≥ (similarity threshold), form a new case library with the filtered cases. Step 6: Secondary case retrieval. Sort the similarity degrees from largest to smallest and take the top œÉ cases as similar cases. Determine the coal spontaneous combustion hazard grades on the basis of the majority rule principle. If there is a case with a similarity of 1 to X in D , take the case as the matching one for X ." ;
        nif:beginIndex            "30275"^^xsd:nonNegativeInteger ;
        nif:endIndex              "31884"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.3.1." ;
        dct:source                "" ;
        dct:title                 "Modeling Building" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_31899_31937>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Step 3 Developing the Case Base Step 5" ;
        nif:beginIndex            "31899"^^xsd:nonNegativeInteger ;
        nif:endIndex              "31937"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Data preprocessing" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_36852_37859>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "The data was divided into two sets, with the first 70% used as the training set to create and train the SO-PCA-clustering-CBR model, and the remaining 30% used as the test set to evaluate the model performance. Accuracy and recall are commonly used indicators to evaluate the predictive ability of classification models. They are calculated through a confusion matrix, as demonstrated in Figure 6. The confusion matrix is widely used to evaluate the prediction precision of classification models in binary classification. For the confusion matrix of multi-class classification problems, each category is successively considered as positive, while other categories are considered as negative, thus converting the multi-class classification problem into multiple binary classification problems [52]. The specific schematic diagram is shown in Figure 6. Accuracy and F1 are also cited in this study to evaluate the prediction performance of machine learning models, and the calculation formulas are as follows:" ;
        nif:beginIndex            "36852"^^xsd:nonNegativeInteger ;
        nif:endIndex              "37859"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "4.1." ;
        dct:source                "" ;
        dct:title                 "Dataset Division and Evaluation Indicators" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_15724_15724>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "" ;
        nif:beginIndex            "15724"^^xsd:nonNegativeInteger ;
        nif:endIndex              "15724"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.3." ;
        dct:source                "" ;
        dct:title                 "Data PreProcessing" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_40614_40614>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "" ;
        nif:beginIndex            "40614"^^xsd:nonNegativeInteger ;
        nif:endIndex              "40614"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5." ;
        dct:source                "" ;
        dct:title                 "Results and Discussions" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_50164_55645>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "To calculate the relative importance of coal spontaneous combustion characteristic variables, this manuscript took SO-PCA-FC-CBR as the target function and adopted the random balance design Fourier amplitude sensitivity test (RBD-FAST) method to carry out sensitivity analysis on characteristic variables. RBD-FAST is a method used to reduce computational costs by implementing the latest developed Fourier amplitude sensitivity test (FAST) using random balance design (RBD) technology [56]. All parameters were set to the same frequency and then reorganized after sampling. Fast Fourier Transform (FFT) was used for the model output based on the previous reorganization sequence. The first-order sensitivity analysis results of corresponding parameters were recorded [57]. In this method, the changes in the results can be simplified as follows: where V x i is the first-order influence of the input factor x i based on the method. V(Y) represents the total variance of SO-PCA-Clustering-CBR. The relative importance of input variables is shown in Figure 14. It can be seen that CO is the most important input variable with a relative importance score of 0.28, followed by CO/‚àÜO 2 (0.23), C 2 H 4 /C 2 H 6 (0.19) and C 2 H 4 (0.17). O 2 (0.13) is the least sensitive predictive factor. The figure illustrates that CO is the most important factor affecting the coal spontaneous combustion hazard grades and this is consistent with the research results of many scholars, but at present, most of the methods used to reach this conclusion have been obtained by observing the chemical reaction of coal molecules and the change law of gas in the temperature program [58][59][60]. However, in this paper, the relative importance of CO is quantified by the RBD-FAST method, and this conclusion is justified by specific values. This method can also be utilized to determine the gases with the greatest relative importance in each stage of coal autogenous combustion, and thus to select the signature gases for each stage of coal autogenous combustion. With the continuous deepening of research in this field, scholars have found more and more factors that influence the spontaneous combustion hazard class of coal [61,62]. However, most of the methods have also been obtained by analyzing the experimental results, which cannot illustrate the importance of the gas in a quantitative manner, while the RBD-FAST method can make up for this shortcoming, providing scholars with a quantitative method to illustrate the newly found importance of the discovered gases through numerical values, which makes the obtained conclusions more convincing. In addition, scholars have established different coal spontaneous combustion stage division systems [41,44], and selected different signature gases in different stages as the basis of discrimination; however, most of the characteristic gas selection methods are based on the change law of different gases in the programmed temperature experiment of coal and the possible chemical reaction of coal molecular groups, but this method does not have specific values, resulting in a lack of persuasion. The RBF-FAST method can quantify the relative importance of each gas at each stage of coal spontaneous combustion, and provide data support for the establishment of coal spontaneous combustion early warning systems. V is the first-order influence of the input factor i x based on the method. ( ) V Y represents the total variance of SO-PCA-Clustering-CBR. The relative importance of input variables is shown in Figure 14. It can be seen that CO is the most important input variable with a relative importance score of 0. The figure illustrates that CO is the most important factor affecting the coal spontaneous combustion hazard grades and this is consistent with the research results of many scholars, but at present, most of the methods used to reach this conclusion have been obtained by observing the chemical reaction of coal molecules and the change law of gas in the temperature program [58,59,60]. However, in this paper, the relative importance of CO is quantified by the RBD-FAST method, and this conclusion is justified by specific values. This method can also be utilized to determine the gases with the greatest relative importance in each stage of coal autogenous combustion, and thus to select the signature gases for each stage of coal autogenous combustion. With the continuous deepening of research in this field, scholars have found more and more factors that influence the spontaneous combustion hazard class of coal [61,62]. However, most of the methods have also been obtained by analyzing the experimental results, which cannot illustrate the importance of the gas in a quantitative manner, while the RBD-FAST method can make up for this shortcoming, providing scholars with a quantitative method to illustrate the newly found importance of the discovered gases through numerical values, which makes the obtained conclusions more convincing. In addition, scholars have established different coal spontaneous combustion stage division systems [41,44], and selected different signature gases in different stages as the basis of discrimination; however, most of the characteristic gas selection methods are based on the change law of different gases in the programmed temperature experiment of coal and the possible chemical reaction of coal molecular groups, but this method does not have specific values, resulting in a lack of" ;
        nif:beginIndex            "50164"^^xsd:nonNegativeInteger ;
        nif:endIndex              "55645"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.4." ;
        dct:source                "" ;
        dct:title                 "Variable Importance" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_30274_30274>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "" ;
        nif:beginIndex            "30274"^^xsd:nonNegativeInteger ;
        nif:endIndex              "30274"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.3." ;
        dct:source                "" ;
        dct:title                 "Modeling Building and Hyperparameter Tuning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_45152_45500>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "To further analyze the prediction results, three sets of comparisons were conducted in this manuscript. Firstly, to verify that Kmeans can cut the computational cost of the model at the expense of lower prediction accuracy, the first set of comparisons was conducted. Secondly, to demonstrate the superiority of FC over Kmeans, a second set of com-" ;
        nif:beginIndex            "45152"^^xsd:nonNegativeInteger ;
        nif:endIndex              "45500"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3.2." ;
        dct:source                "" ;
        dct:title                 "Comparison of Subgroups" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_28652_30273>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "The traditional PCA-clustering-CBR model is a hybrid model that applies PCA and clustering to CBR. To some extent, this model solves the problem that the weights of case characteristic attributes are difficult to determine in the traditional CBR model and the case retrieval efficiency is reduced as the case increases in the case base. The PCA-clustering-CBR model first adopts the PCA algorithm to calculate the basic weights of case characteristic attributes and applies them to the calculation of similarity, which increases the calculation accuracy and improves the prediction ability. In order to improve the efficiency of case retrieval, a clustering algorithm is used to divide n cases in the case base into k clusters with cluster centers serving as representative cases. The mean value of each data point in each cluster is taken. When a new problem arises, it is first compared with cluster centers, and then assigned to the most relevant cluster, where the entire CBR process is conducted. However, this model may cause the loss of cluster boundary information, reducing the prediction ability of the machine learning model and affecting its generalization ability. To find a solution to the aforementioned problem, we introduced fuzzy clustering into CBR to construct the PCA-FC-CBR model. The case base was divided into sets of fuzzy clusters with overlapping boundaries, allowing any case to belong to multiple clusters simultaneously. During the prediction process, cases are screened based on their membership degree with respect to the cluster centers, thereby reducing the loss of boundary information." ;
        nif:beginIndex            "28652"^^xsd:nonNegativeInteger ;
        nif:endIndex              "30273"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.2." ;
        dct:source                "" ;
        dct:title                 "PCA-FC-CBR" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_22938_26656>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "The Snake Optimization (SO) algorithm is a new metaheuristic algorithm proposed by Fatma A. Hashim et al. in 2022 [49]. This algorithm is inspired by the mating behavior of snakes in nature. Compared with other algorithms, SO has higher precision and faster iteration speed [50]. The algorithm includes the following four stages: initialization stage, selection stage, exploration stage and development stage (see Figure 4). The specific process is as follows. Step 1: Initialization stage. Generate an initial population using Equation (10), and then divide the population into female and male two swarms using Equations ( 11) and ( 12). where x i represents the location of the ith individual; r is the random number between 0 and 1; x max and x min are the upper and lower limits for x; N represents the number of individuals; N m denotes the number of individuals in the male population, while N f denotes the number of individuals in the female population. Step 2: Selection stage. By calculating the temperature T emp and food quantity Q, the search stage is selected. T emp and Q are calculated using Equations ( 13) and ( 14), respectively. where t denotes the number of present iterations; T is the maximum number of iterations; C 1 is a constant of 0.5. Step 3: Exploration stage. When the food quantity Q is below the threshold, male snakes update their positions using Equations ( 15) and ( 16), while female snakes update their positions using Equations ( 17) and (18). where X i,m and X i, f are the locations of the ith male and female snakes, respectively; X rand,m and X rand, f are the randomly selected locations of male and female snakes. c 2 is a constant that is set as 0.05; A m and A f represent the ability of male and female snakes to search for food; rand is a random number between 0 and 1. f rand,m and f rand, f are the fitness of X rand,m and X rand, f ; f i,m and f i, f represent the fitness of the ith individuals of male and female snakes. Step 4: Development stage. When the food quantity Q is greater than the threshold, the development stage is divided into two parts according to the temperature. When the temperature is greater than the threshold, the snake is in a thermal state and it only searches for food. The position update equation is shown as follows: where X i,j (t + 1) represents the location of the female or male snake; X f ood is the best individual location and c 3 is a constant that is set as 0.05. As the number of iterations increases, the temperature decreases gradually. When the temperature is lower than the threshold, the snake is in a cold state. In this state, the snake updates its position through fighting or mating. The equation for updating the position in fight mode is shown in Equation (20). where X i,m (t + 1) and X i, f (t + 1) denote the locations of the ith male and female snakes. X best,m and X best, f denote the best location of male and female snakes. FM and FF represent the fighting capability of the male and female snakes, which are calculated via Equation (21). where f best,m and f best, f represent the fitness of the best male and female snakes; f i represents the fitness of individual i. Fire 2024, 7, 107 10 of 25   The updated position equation for the mating mode is depicted as follows: where X i,m (t) and X i, f (t) are the locations of the ith snakes in the male and female swarms, respectively; M m and M f are the mating competence values of male and female snakes, which are calculated as follows: If the snake eggs hatch, the worst individuals in the male swarm and female swarm are exchanged using the following equation: where X worst,m and X worst, f represent the worst individuals in male and female swarms." ;
        nif:beginIndex            "22938"^^xsd:nonNegativeInteger ;
        nif:endIndex              "26656"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1.3." ;
        dct:source                "" ;
        dct:title                 "SO" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_36851_36851>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "" ;
        nif:beginIndex            "36851"^^xsd:nonNegativeInteger ;
        nif:endIndex              "36851"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "4." ;
        dct:source                "" ;
        dct:title                 "Experiments" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_55646_58036>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "In this study, a new method used to obtain coal spontaneous combustion hazard grades is proposed based on the changing law of the concentration of various signature gases in the process of coal spontaneous combustion, and a prediction model of coal spontaneous combustion hazard grades is established. The findings can be summarized as follows: (1) By analyzing the change rule of the experimental data of heating up coal in the spontaneous combustion procedure, six characteristic temperatures and their thresholds were determined, and the hazard classes of coal were classified into six classes: green (0), blue (1), purple (2), yellow (3), orange (4), and red (5). (2) MeanRadius-SMOTE can be adopted to address the imbalance of the dataset. By comparing the predictive ability of four prediction models on different datasets, it was found that the proposed method performs the best when compared to the SMOTE and Kmeans-SMOTE methods. (3) Three sets of comparative experiments were conducted in this research to compare the performance of different machine learning models in predicting coal spontaneous combustion hazard grades. The experimental results indicate that (1) the traditional PCA-Clustering-CBR model reduces the computational cost but also causes boundary information loss, resulting in lower prediction accuracy of machine learning models; (2) compared with the traditional PCA-Clustering-CBR, fuzzy clustering avoids the loss of boundary information and improves the computational efficiency of the model without affecting the prediction accuracy; and (3) PCA can improve the prediction accuracy of machine learning models by calculating characteristic attribute weights based on the cumulative contribution rate. (4) Aiming at the multi-objective optimization problem of the PCA-FM-CBR model, this manuscript adopted the SO algorithm to optimize Œ≥ 1 , Œ≥ 2 and œÉ of the PCA-FM-CBR model step by step. The optimization shows that the model demonstrates optimal performance when the values of Œ≥ 1 , Œ≥ 2 and œÉ are 0.71, 0.39, and 2, respectively. The calculation cost is reduced to the greatest extent. (5) RBD-FAST was used to conduct sensitivity analysis for input variables, and the results demonstrated that CO is the most important input variable with a relative importance score of 0.28. Therefore, attention should be paid to CO in practical underground engineering." ;
        nif:beginIndex            "55646"^^xsd:nonNegativeInteger ;
        nif:endIndex              "58036"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "6." ;
        dct:source                "" ;
        dct:title                 "Conclusions" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_19369_19369>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "" ;
        nif:beginIndex            "19369"^^xsd:nonNegativeInteger ;
        nif:endIndex              "19369"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1." ;
        dct:source                "" ;
        dct:title                 "Overview of the Machine Learning Models" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_43421_45151>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "In order to verify the performance of the model proposed in this manuscript, five single models (SVM, RF, Bayesian, GBDT and CBR) and two hybrid models (SO-PCA-Kmeans-CBR and SO-Kmeans-CBR) were compared with each other by using them to predict coal spontaneous combustion hazard grades. Table 5 shows the F1, recall, and accuracy of SO-PCA-FC-CBR and other models at each intensity grade (0-5 levels) of coal spontaneous combustion. In the prediction of initial values for warning, SO-PCA-FC-CBR has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. In the prediction of gray warning, SO-PCA-FC-CBR has the highest F1-score, recall, and accuracy of 0.98, 1, and 0.97, respectively. In the prediction of blue warning, CBR and RF have the highest accuracy of 1, while SO-PCA-FC-CBR has the highest F1-score and recall of 0.97 and 0.97, respectively. In the prediction of yellow warning, RF has the highest recall of 1, while SO-PCA-FC-CBR has the highest F1-score and accuracy of 1 and 0.98, respectively. In the prediction of orange warning, SVM has the highest F1 of 1, SO-PCA-FC-CBR has the highest recall of 0.81 and RF has the highest accuracy of 1. In the prediction of red warning, SVM has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. Overall, SO-PCA-FC-CBR shows the best predictive performance for all of the six coal spontaneous combustion hazard grades. Figure 10 shows the overall accuracy of five single models, two hybrid models and the model proposed in this manuscript. Evidently, the SO-PCA-FC-CBR model possesses the highest overall accuracy of 95%, demonstrating the superiority of the proposed algorithm in predicting coal spontaneous combustion hazard grades." ;
        nif:beginIndex            "43421"^^xsd:nonNegativeInteger ;
        nif:endIndex              "45151"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3.1." ;
        dct:source                "" ;
        dct:title                 "Comparison between SO-PCA-Clustering-CBR and Other Models" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_42779_43419>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "In order to verify the performance of the model proposed in this m single models (SVM, RF, Bayesian, GBDT and CBR) and two hybrid mo Kmeans-CBR and SO-Kmeans-CBR) were compared with each other by predict coal spontaneous combustion hazard grades. Table 5 shows the F1 curacy of SO-PCA-FC-CBR and other models at each intensity grade (0-5 spontaneous combustion. In the prediction of initial values for warning, SO has the highest F1-score, recall, and accuracy of 1, 1, and 1, respectively. In of gray warning, SO-PCA-FC-CBR has the highest F1-score, recall, and ac 1, and 0.97, respectively. In the prediction of blue warning, CBR and RF h" ;
        nif:beginIndex            "42779"^^xsd:nonNegativeInteger ;
        nif:endIndex              "43419"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3.1." ;
        dct:source                "" ;
        dct:title                 "Comparison between SO-PCA-Clustering-CBR and Other Models" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_17631_19367>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "As shown in Section 2.2, the initial coal spontaneous combustion dataset is imbalanced, which may lead machine learning models to misclassify minority class samples as majority class samples, thereby affecting their prediction performance. Hence, it is necessary to perform over-sampling with the initial coal spontaneous combustion database. In this manuscript, the MeanRadius-SMOTE algorithm was used to generate new data to achieve balance between various coal spontaneous combustion data [45]. The MeanRadius-SMOTE algorithm modifies the generation rule of the SMOTE algorithm by considering the radius and geometric center when generating new data. As a result, the new samples are more likely to be distributed around the average radius of the minority class samples. This algorithm is not only efficient for datasets of any shape dataset, but also the generated new data are more likely to be distributed near the average radius of the minority class samples, which can improve the ability of machine learning models to identify the decision boundary. The steps of MeanRadius-SMOTE for generating new data are as follows: (  Fire 2024, 7, 107 7 of 25 (5) Repeat Steps 3 and 4 until the sample size of the majority and minority class is balanced. In order to ensure that the generated data are valid, we assigned k as 3 and r as 2 (which is obtained through multiple experiments). After balancing the dataset, 91 new green warning data, 71 blue warning data, 4 yellow warning data, 38 orange warning data, and 71 red warning data were newly generated. The new coal spontaneous combustion database has a total of 510 coal spontaneous combustion data, and the quantity ratio for coal spontaneous combustion of Grades 0-5 is 1:1:1:1." ;
        nif:beginIndex            "17631"^^xsd:nonNegativeInteger ;
        nif:endIndex              "19367"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.3.2." ;
        dct:source                "" ;
        dct:title                 "MeanRadius-SMOTE" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_41900_42777>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "Figure 8 shows the iterative process of the SO algorithm searching for the maximum accuracy. It can be seen that as the SO algorithm iterates, the accuracy gradually increases, indicating that the SO algorithm is effective at optimizing the hyperparameters of the SO-PCA-FC-CBR hybrid model. The accuracy is the lowest (0.71) at the first iteration, and it increases to 0.95 at the 36th iteration. Figure 9 demonstrates the iterative process of the SO algorithm searching for the minimum number of comparisons. The figure illustrates that as the SO algorithm iterates, the number of comparisons gradually decreases, indicating that the SO algorithm is also effective at improving the computational efficiency of the SO-PCA-FC-CBR hybrid model. The number of comparisons is the highest at the first iteration, which is 78,752, and then decreases to 45,000 at the 45th iteration." ;
        nif:beginIndex            "41900"^^xsd:nonNegativeInteger ;
        nif:endIndex              "42777"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.2." ;
        dct:source                "" ;
        dct:title                 "Parameter Tuning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_49314_50163>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "To calculate the relative importance of coal spontaneous combustion characteristic variables, this manuscript took SO-PCA-FC-CBR as the target function and adopted the random balance design Fourier amplitude sensitivity test (RBD-FAST) method to carry out sensitivity analysis on characteristic variables. RBD-FAST is a method used to reduce computational costs by implementing the latest developed Fourier amplitude sensitivity test (FAST) using random balance design (RBD) technology [56]. All parameters were set to the same frequency and then reorganized after sampling. Fast Fourier Transform (FFT) was used for the model output based on the previous reorganization sequence. The firstorder sensitivity analysis results of corresponding parameters were recorded [57]. In this method, the changes in the results can be simplified as follows: ( )" ;
        nif:beginIndex            "49314"^^xsd:nonNegativeInteger ;
        nif:endIndex              "50163"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.4." ;
        dct:source                "" ;
        dct:title                 "Variable Importance" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_42778_42778>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "" ;
        nif:beginIndex            "42778"^^xsd:nonNegativeInteger ;
        nif:endIndex              "42778"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3." ;
        dct:source                "" ;
        dct:title                 "Model Comparison Analysis" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_34007_35687>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "The effectiveness of machine learning models largely depends on parameter selection. If parameters are selected based on empirical selection or grid search, deep learning models may experience overfitting or underfitting. Furthermore, since there are many hyperparameters, it is often difficult to set their values through experience alone. Therefore, the SO algorithm was adopted to identify the hyperparameters in the PCA-clustering-CBR hybrid model in this research. Table 3 displays the hyperparameters in PCA-clustering-CBR that require adjustment and their respective ranges of values. The number of iterations was set as 100 with 10 individuals in each generation. All parameters in the SO algorithm were set through experimental testing. During hyperparameter tuning, each set of hyperparameters is represented by a snake in the SO algorithm. The SO algorithm was adopted to update the position of each snake by using different optimization formulas at different stages. Hence, the fitness value was minimized. When meeting the termination condition, the optimal hyperparameters were selected. To ensure both the computational efficiency and prediction precision of the model, the authors set the accuracy rate and the number of comparisons as the objective function. For multiple objective functions, the optimization process was set as follows: (1) initialize the parameters of the SO algorithm. (2) Use the accuracy rate as the objective function to find the optimal parameter for PCA-clustering-CBR. (3) Find the optimal parameter for PCA-clustering-CBR by setting the highest accuracy as the limiting condition and the number of comparisons as the objective function." ;
        nif:beginIndex            "34007"^^xsd:nonNegativeInteger ;
        nif:endIndex              "35687"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.3.2." ;
        dct:source                "" ;
        dct:title                 "Hyperparameter Tuning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_11295_15723>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "This paper is based on the classification standard of the coal spontaneous combustion hazard class proposed by scholars, combined with the law of collecting the signature gas in the data of coal spontaneous combustion. Article 261 of the Coal Mine Safety Regulations requires the determination of the signifying gas of natural ignition of coal seams as well as the critical value. Article 265 stipulates that the operation must be stopped when there is a sign of ignition, and Article 275 stipulates that when there is a fire, it should be extinguished immediately according to the nature of the fire and other circumstances. These three articles qualitatively describe the signature gases of spontaneous coal combustion, signs of ignition, and fire, but lack a quantitative method of judgment. Pan [43] divided the stage of spontaneous coal combustion into four stages, but the division criteria are vague and not detailed enough; therefore, we took Pan's criteria as the basis, combined with the division criteria established in the papers published by Duo [41] and Fei [44], and obtained the division criteria in Table 1, which divide the stage of spontaneous coal combustion into six stages, with a higher concentration of O 2 and a lower concentration of CO as the first stage. When CO appears, it is the second stage, when C 2 H 4 gas appears, it is the third stage, when CO/‚àÜO 2 shows an increasing state, it is the fourth stage, a constant C 2 H 4 /C 2 H 6 value, and a decreasing O 2 concentration is the fifth stage, and a maximum C 2 H 4 /C 2 H 6 value is the sixth stage. Figure 1a shows that the O 2 concentration with the increase in temperature shows an overall decreasing trend and when the temperature is less than 50 degrees Celsius, the O 2 concentration is higher, which indicates that the spontaneous combustion of coal at this time is in the first stage. Figure 1b shows that with the increase in temperature, the CO concentration shows an overall increasing trend and when the temperature is greater than 50 degrees Celsius, the CO concentration begins to fluctuate, which indicates that the spontaneous combustion of coal is in the second stage. Figure 1c shows that the C 2 H 4 concentration increases with temperature, and when the temperature is greater than 60 ‚Ä¢ C, the C 2 H 4 concentration fluctuates slightly, which indicates that the spontaneous combustion of coal is in the third stage. Figure 1d shows that CO/‚àÜO 2 increases with temperature, and when the temperature is less than 100 ‚Ä¢ C, the CO/‚àÜO 2 value increases with temperature. When the temperature is greater than 100 ‚Ä¢ C, CO/‚àÜO 2 shows a rapid increase with the increase in temperature, which indicates that the spontaneous combustion of coal is in the fourth stage. Figure 1e shows that the C 2 H 4 /C 2 H 6 concentration with the increased temperature shows an overall increasing trend and when the temperature is between 120 ‚Ä¢ C and 230 ‚Ä¢ C, C 2 H 4 /C 2 H 6 shows an increasing trend with the increase in temperature, which indicates that the spontaneous combustion of coal is in the fifth stage, and when the temperature is greater than 230 ‚Ä¢ C, the highest value appears, which indicates that the spontaneous combustion of coal is in the sixth stage. According to the non-linear relationship between gas and temperature shown in Figure 1, combined with the classification criteria in Table 1, the six stages of coal spontaneous combustion correspond to six warning grades, thus selecting 50 ‚Ä¢ C, 60 ‚Ä¢ C, 100 ‚Ä¢ C, 120 ‚Ä¢ C, 230 ‚Ä¢ C as the temperature thresholds and classifying combustion hazards. The six stages of coal spontaneous combustion correspond to six warning grades, so that 50 ‚Ä¢ C, 60 ‚Ä¢ C, 100 ‚Ä¢ C, 120 ‚Ä¢ C and 230 ‚Ä¢ C are selected as the temperature thresholds, and the combustion hazard grades are divided into six levels: green, blue, purple, yellow, orange and red. The coal spontaneous combustion hazard grades are shown in Table 2. Figure 2 shows that the data in the coal spontaneous combustion hazard grades database exhibit obvious unbalancedness. The proportions for Grades 0-5 are 3.2% (11 cases), 9.2% (31 cases), 30.3% (102 cases), 29.1% (98 cases), 18.9% (64 cases) and 9.2% (31 cases), respectively.    The sixth stage 230 T ‚â• Red warning (5) Figure 2 shows that the data in the coal spontaneous combustion hazard grades database exhibit obvious unbalancedness. The proportions for Grades 0-5 are 3.2% (" ;
        nif:beginIndex            "11295"^^xsd:nonNegativeInteger ;
        nif:endIndex              "15723"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.2." ;
        dct:source                "" ;
        dct:title                 "Classification of Coal Spontaneous Combustion Hazard Grades" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_19370_20105>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Case-based reasoning (CBR) is a machine learning algorithm proposed by Aamodt and Plaza et al. in 1994 that mimics the analogical reasoning in the human brain [46]. CBR consists of four basic processes: case representation, case retrieval, case reuse and case retain [30,47]. The schematic diagram of CBR is depicted in Figure 3, and the specific steps are as follows: , 7, 107 8 of 27 Step 3: Sort the similarity values in descending order, and select the top œÉ cases 1 T , 3 T , ‚Ä¶, T œÉ as similar cases. According to the reuse principle, Equation ( 6) was used to obtain the result. Step 4: Store the corresponding target cases and results in the historical case base to complete the knowledge storage and experience learning of CBR." ;
        nif:beginIndex            "19370"^^xsd:nonNegativeInteger ;
        nif:endIndex              "20105"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1.1." ;
        dct:source                "" ;
        dct:title                 "Case-Based Reasoning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_3618_9356>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Coal spontaneous combustion, as a common coal mine accident, seriously threatens the lives of coal mine workers and the property safety of mining equipment [1][2][3]. In addition, coal spontaneous combustion also pollutes the soil and destroys the ecological environment [4][5][6]. In recent years, with the depletion of shallow mineral resources, more and more underground coal mine projects are going deeper underground at an unprecedented speed [7][8][9], causing coal spontaneous combustion to become a serious threat to many projects worldwide [10][11][12][13]. To prevent and control coal spontaneous combustion disasters, it is necessary to study the effective prediction of the coal spontaneous combustion method. The gas analysis method, as a commonly used method for predicting spontaneous coal combustion [14], has the advantage of strong operability [15], and is widely used in the prediction of coal spontaneous combustion. This method mainly tests the signature gases generated during the coal heating process and the concentration and finds the variation relationship between it and the coal temperature, thereby indirectly predicting the actual temperature [16]. However, it was found that the relationship between the signature gases' concentration and coal temperature is non-linear [17], and it is very difficult to describe this relationship through the most commonly used mathematical methods. To solve this problem, scholars have applied machine learning to the prediction of spontaneous coal combustion, which, as a branch of artificial intelligence, can better mine the nonlinear relationship between indicators and samples [18]. Zhang [19] proposed a prediction model based on RF and MLP, which can accurately predict coal temperature. However, the model is greatly affected by the value of hyperparameters. Guo [20] and Wang [21] used PSO to calculate the hyperparameters in the GRU and BPNN algorithms, respectively, and established PSO-GRU and PSO-BPNN temperature prediction models. The results show that the models have good prediction ability. Li [22] improved the optimization ability of the GA algorithm and combined it with a neural network to establish a temperature prediction model. The results show that the improved GA algorithm can improve the prediction accuracy of the model. Nonetheless, the aforementioned models have the following limitations: (1) a large number of training samples are required, and the calculation complexity of the model is high, leading to prolonged computational time; (2) most machine learning models do not have self-learning abilities; and (3) they are prone to overfitting during modeling. Therefore, further research is needed to explore new prediction methods. In addition, all of the above studies are quantitative, focusing on predicting coal temperatures, and there are fewer studies on predicting the coal spontaneous combustion hazard grades. As a mature branch of artificial intelligence, case-based reasoning (CBR) has been widely applied in other fields [23]. CBR has greater classification performance compared with traditional data mining methods [24] and it has also shown excellent performance in fields like fault diagnosis [25][26][27], risk assessment [28,29], and forest fire prediction [30][31][32]. It should be noted that the weights of case characteristic attributes in CBR have a significant impact on the prediction performance of the model. However, the calculation of weights lacks a solid foundation and is strongly influenced by subjective factors. In addition, as the number of cases in case-based reasoning becomes larger, the computational cost of CBR gradually increases and the computational efficiency gradually decreases. To address this issue, scholars have applied clustering to the CBR case library [33][34][35], dividing the case library into several different clusters and limiting the CBR process to specific clusters, which reduces the comparison times and lowers the computational cost. However, this method may lead to the loss of cluster boundary information and result in a lower accuracy of model prediction [36]. In addition, concerning the determination of the coal spontaneous combustion hazard grades, scholars have proposed various methods for determining the coal spontaneous combustion hazard grades [37][38][39]. However, due to the different geological structures, mining environments, coal quality composition, and other factors in different coal mines, there are great differences in the numerical values of the same gas indexes, resulting in the absence of a fixed value for the threshold of the coal spontaneous combustion hazard grades, which also poses a challenge to the prediction of the coal spontaneous combustion hazard grades. Although the CBR model possesses good prediction performance in other fields, it has been seldom applied to coal spontaneous combustion hazard grade prediction. Furthermore, there are efficiency bottlenecks and a lack of basis for the weights of case characteristic attributes in the CBR model. In addition, there are some limitations in the current method of classifying the risk level of spontaneous coal combustion. There are also limitations in the current methods of classifying the coal spontaneous combustion hazard grades. Therefore, to address the shortcomings of existing research, the following studies were conducted by the authors of this manuscript: (1) Through analyzing the change rule of signature gases in the process of coal warming, the method of coal spontaneous combustion hazard grade classification was proposed; (2) adaption of PCA to calculate the weights of case characteristic attributes; (3) application of fuzzy clustering to the CBR model to" ;
        nif:beginIndex            "3618"^^xsd:nonNegativeInteger ;
        nif:endIndex              "9356"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "1." ;
        dct:source                "" ;
        dct:title                 "Introduction" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_20106_21852>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "The fuzzy c-means clustering (FCM) algorithm is a clustering algorithm based on objective functions [48]. This algorithm introduces membership functions on the basis of the K-Means algorithm, which can better indicate the similarity between a sample and a certain cluster. The FCM objective function is shown in Equation ( 7). ( ) ( , ) where c is the total number of all categories; m is the weighting fuzziness parameter that is set as 2 in this manuscript; n represents the number of cases in the case base; ik u denotes the membership degree of the k th case with respect to the i th category; 2 ( , ) j i d x v is the distance between the k th case and the ith cluster center. Using the Lagrange multiplier method, the iterative formulas for ik u and i v were obtained as follows. Step 1: Assume that the source cases in the historical database are represented in the following binary format: where m denotes the sum of historical cases; X k denotes the case characteristic attribute; x k is the characteristic data from case descriptions; Y k is the case category. Step 2: Calculate the similarity between the new case and the cases in the case base using Equation (5). where Œ∏ i represents the weights of case characteristic attributes and it is typically set as 1 o . The value of Œ∏ i indicates the contribution degree of a specific characteristic attribute to the overall case. Step 3: Sort the similarity values in descending order, and select the top œÉ cases T 1 , T 2 , T 3 , . . ., T œÉ as similar cases. According to the reuse principle, Equation ( 6) was used to obtain the result. Step 4: Store the corresponding target cases and results in the historical case base to complete the knowledge storage and experience learning of CBR." ;
        nif:beginIndex            "20106"^^xsd:nonNegativeInteger ;
        nif:endIndex              "21852"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1.2." ;
        dct:source                "" ;
        dct:title                 "FCM" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_16150_17208>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "As shown in Section 2.2, the initial coal spontaneous combustion dataset is imbalanced, which may lead machine learning models to misclassify minority class samples as majority class samples, thereby affecting their prediction performance. Hence, it is necessary to perform over-sampling with the initial coal spontaneous combustion database. In this manuscript, the MeanRadius-SMOTE algorithm was used to generate new data to achieve balance between various coal spontaneous combustion data [45]. The MeanRadius-SMOTE algorithm modifies the generation rule of the SMOTE algorithm by considering the radius and geometric center when generating new data. As a result, the new samples are more likely to be distributed around the average radius of the minority class samples. This algorithm is not only efficient for datasets of any shape dataset, but also the generated new data are more likely to be distributed near the average radius of the minority class samples, which can improve the ability of machine learning models to identify the decision boundary." ;
        nif:beginIndex            "16150"^^xsd:nonNegativeInteger ;
        nif:endIndex              "17208"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2.3.2." ;
        dct:source                "" ;
        dct:title                 "MeanRadius-SMOTE" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_31938_32001>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "Step 4 Assigning the Attribute Weights Step 6 Fristly retrieval" ;
        nif:beginIndex            "31938"^^xsd:nonNegativeInteger ;
        nif:endIndex              "32001"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Secondary retrieval" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_9357_9357>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "" ;
        nif:beginIndex            "9357"^^xsd:nonNegativeInteger ;
        nif:endIndex              "9357"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "2." ;
        dct:source                "" ;
        dct:title                 "Dataset Preparation" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_32002_34006>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "The effectiveness of machine learning models largely depends on parameter selection. If parameters are selected based on empirical selection or grid search, deep learning models may experience overfitting or underfitting. Furthermore, since there are many hyperparameters, it is often difficult to set their values through experience alone. Therefore,  Step 1: Collect coal spontaneous combustion data, screen prediction indicators for coal spontaneous combustion, and analyze the data to build a raw coal spontaneous combustion data base. Step 2: Data preprocessing. Initially, stratify the hazard grades associated with spontaneous coal combustion. Subsequently, apply dimensionless normalization to the dataset. Finally, equalize the dataset distribution through the implementation of the MeanRadius-SMOTE algorithm. Step 3: Divide the coal spontaneous combustion data into a training set and a test set, using the training set data to construct a coal spontaneous combustion database. The test set data are used to verify the model's performance. Apply the FCM algorithm to perform fuzzy clustering on the coal spontaneous combustion database, obtaining cluster centers and membership functions. Construct a fuzzy clustering CBR model. Step 4: Set the cumulative contribution rate and calculate the weights of each case characteristic attribute using PCA. Step 5: Primary case retrieval. Firstly, screen out the cluster centers whose similarity with the new case is no less than Œ≥ 1 (similarity threshold). Secondly, screen out all cases whose membership degree with cluster centers is greater than Œ≥ 2 (similarity threshold), form a new case library with the filtered cases. Step 6: Secondary case retrieval. Sort the similarity degrees from largest to smallest and take the top œÉ cases as similar cases. Determine the coal spontaneous combustion hazard grades on the basis of the majority rule principle. If there is a case with a similarity of 1 to X in D, take the case as the matching one for X." ;
        nif:beginIndex            "32002"^^xsd:nonNegativeInteger ;
        nif:endIndex              "34006"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.3.2." ;
        dct:source                "" ;
        dct:title                 "Hyperparameter Tuning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_43420_43420>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "" ;
        nif:beginIndex            "43420"^^xsd:nonNegativeInteger ;
        nif:endIndex              "43420"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "5.3." ;
        dct:source                "" ;
        dct:title                 "Model Comparison Analysis" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_35688_36850>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "The data was divided into two sets, with the first 70% used as the training set to create and train the SO-PCA-clustering-CBR model, and the remaining 30% used as the test set to evaluate the model performance. Accuracy and recall are commonly used indicators to evaluate the predictive ability of classification models. They are calculated through a confusion matrix, as demonstrated in Figure 6. The confusion matrix is widely used to evaluate the prediction precision of classification models in binary classification. For the confusion matrix of multi-class classification problems, each category is successively considered as positive, while other categories are considered as negative, thus converting the multi-class classification problem into multiple binary classification problems [52]. The specific schematic diagram is shown in Figure 6. the parameters of the SO algorithm. ( 2) Use the accuracy rate as the objective function to find the optimal parameter for PCA-clustering-CBR. (3) Find the optimal parameter for PCA-clustering-CBR by setting the highest accuracy as the limiting condition and the number of comparisons as the objective function." ;
        nif:beginIndex            "35688"^^xsd:nonNegativeInteger ;
        nif:endIndex              "36850"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "4." ;
        dct:source                "" ;
        dct:title                 "Experiments 4.1. Dataset Division and Evaluation Indicators" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_21853_22937>
        a                         <dfki:ScientificDocumentPart> , nif:OffsetBasedString ;
        nif:anchorOf              "The fuzzy c-means clustering (FCM) algorithm is a clustering algorithm based on objective functions [48]. This algorithm introduces membership functions on the basis of the K-Means algorithm, which can better indicate the similarity between a sample and a certain cluster. The FCM objective function is shown in Equation (7). where c is the total number of all categories; m is the weighting fuzziness parameter that is set as 2 in this manuscript; n represents the number of cases in the case base; u ik denotes the membership degree of the kth case with respect to the ith category; d 2 (x j , v i ) is the distance between the kth case and the ith cluster center. Using the Lagrange multiplier method, the iterative formulas for u ik and v i were obtained as follows. The authors set the maximum iterations. When the relevant parameters were input, u ik and v i were continuously updated. When the maximum number of iterations was reached or the set conditions were met, the iterations were stopped. Then, the membership matrix, cluster centers and individual clusters were output." ;
        nif:beginIndex            "21853"^^xsd:nonNegativeInteger ;
        nif:endIndex              "22937"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "3.1.2." ;
        dct:source                "" ;
        dct:title                 "FCM" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "section" .

<http://scilake-project.eu/res/cb0fde5c#offset_0_101>
        a                         nif:OffsetBasedString , <dfki:ScientificDocumentPart> ;
        nif:anchorOf              "Prediction of Coal Spontaneous Combustion Hazard Grades Based on Fuzzy Clustered Case-Based Reasoning" ;
        nif:beginIndex            "0"^^xsd:nonNegativeInteger ;
        nif:endIndex              "101"^^xsd:nonNegativeInteger ;
        nif:referenceContext      <http://scilake-project.eu/res/cb0fde5c> ;
        dct:section_number        "" ;
        dct:source                "" ;
        dct:title                 "Prediction of Coal Spontaneous Combustion Hazard Grades Based on Fuzzy Clustered Case-Based Reasoning" ;
        qont:metadata             []  ;
        scilake:DocumentPartType  "title" .
